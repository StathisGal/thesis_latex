@Comment Soft-NMS                  
@INPROCEEDINGS{DBLP:journals/corr/BodlaSCD17,
author={N. {Bodla} and B. {Singh} and R. {Chellappa} and L. S. {Davis}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Soft-NMS — Improving Object Detection with One Line of Code},
year={2017},
volume={},
number={},
pages={5562-5570},
keywords={computational complexity;computer vision;learning (artificial intelligence);neural nets;object detection;coco-style mAP metric;PASCAL VOC2007;MS-COCO;deformable-RFCN;computational complexity;detection boxes;nonmaximum suppression;object detection pipeline;Soft-NMS;NMS algorithm;Faster-RCNN;detection scores;predefined overlap threshold;Object detection;Proposals;Pipelines;Detectors;Measurement;Feature extraction},
doi={10.1109/ICCV.2017.593},
ISSN={},
month={Oct},}
                  
@Comment MABO introduction                  
@article{DBLP:journals/corr/WinschelLE16,
  author    = {Anton Winschel and
               Rainer Lienhart and
               Christian Eggert},
  title     = {Diversity in Object Proposals},
  journal   = {CoRR},
  volume    = {abs/1603.04308},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.04308},
  archivePrefix = {arXiv},
  eprint    = {1603.04308},
  timestamp = {Mon, 13 Aug 2018 16:47:23 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/WinschelLE16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@Comment Human Action Recognition Survey                  
@article{DBLP:journals/corr/abs-1806-11230,
  author    = {Yu Kong and
               Yun Fu},
  title     = {Human Action Recognition and Prediction: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/1806.11230},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.11230},
  archivePrefix = {arXiv},
  eprint    = {1806.11230},
  timestamp = {Mon, 13 Aug 2018 16:49:09 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1806-11230},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}                  
@Comment Pascal VOC                  
@article{Everingham:2010:PVO:1747084.1747104,
 author = {Everingham, Mark and Gool, Luc and Williams, Christopher K. and Winn, John and Zisserman, Andrew},
 title = {The Pascal Visual Object Classes (VOC) Challenge},
 journal = {Int. J. Comput. Vision},
 volume = {88},
 year = {2010},
 url = {http://dx.doi.org/10.1007/s11263-009-0275-4},
} 
                  
@Comment HMDB dataset                  
@INPROCEEDINGS{Kuehne11,
author={H. {Kuehne} and H. {Jhuang} and E. {Garrote} and T. {Poggio} and T. {Serre}},
booktitle={2011 International Conference on Computer Vision},
title={HMDB: A large video database for human motion recognition},
year={2011},
volume={},
number={},
pages={2556-2563},
keywords={image motion analysis;object recognition;social networking (online);video databases;HMDB;large video database;human motion recognition;computer vision research;static image datasets;image categories;human action datasets;action recognition databases;digitized movies;YouTube;camera motion;viewpoint;video quality;occlusion;Cameras;YouTube;Databases;Training;Visualization;Humans;Motion pictures},
doi={10.1109/ICCV.2011.6126543},
ISSN={},
month={Nov},}                  

                  
@Comment JHMDB dataset                                    
@INPROCEEDINGS{Jhuang:ICCV:2013,
author={H. {Jhuang} and J. {Gall} and S. {Zuffi} and C. {Schmid} and M. J. {Black}},
booktitle={2013 IEEE International Conference on Computer Vision},
title={Towards Understanding Action Recognition},
year={2013},
volume={},
number={},
pages={3192-3199},
keywords={computer vision;gesture recognition;image segmentation;image sequences;pose estimation;action recognition;real-world datasets;video sequences;systematic performance evaluation;thoroughly-annotated data;human actions;joints-for-the HMDB dataset;optical flow;optical segmentation;flow algorithms;human bounding boxes;pose estimation algorithms;feature extraction;J-HMDB;human detection algorithms;computer vision algorithms;Videos;Joints;Trajectory;Estimation;Accuracy;Motion pictures;Vectors;action recognition;dataset;JHMDB;annotation;optical flow estimation;pose estimation},
doi={10.1109/ICCV.2013.396},
ISSN={},
month={Dec},}

@Comment UCF dataset                  
@article{soomro2012ucf101,
    title={UCF101: A dataset of 101 human actions classes from videos in the wild},
    author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
    journal={arXiv preprint arXiv:1212.0402},
    year={2012}
  }                  
               
@Comment Detect and track                  
@INPROCEEDINGS{DBLP:journals/corr/abs-1712-09184,
author={R. {Girdhar} and G. {Gkioxari} and L. {Torresani} and M. {Paluri} and D. {Tran}},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
title={Detect-and-Track: Efficient Pose Estimation in Videos},
year={2018},
volume={},
number={},
pages={350-359},
keywords={object detection;object tracking;pose estimation;tracking;video signal processing;human body keypoints;keypoint estimation;keypoint predictions;multi-person video pose estimation benchmark;human detection;mask R-CNN;detect-and-track;multi-object tracking accuracy metric;MOTA;video pose estimation;Videos;Three-dimensional displays;Electron tubes;Pose estimation;Two dimensional displays;Task analysis;Optimization},
doi={10.1109/CVPR.2018.00044},
ISSN={},
month={June},}
                  
                  
@Comment Mask RCNN                  
@INPROCEEDINGS{DBLP:journals/corr/HeGDG17,
author={K. {He} and G. {Gkioxari} and P. {Dollár} and R. {Girshick}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Mask R-CNN},
year={2017},
volume={},
number={},
pages={2980-2988},
keywords={feature extraction;image segmentation;object detection;pose estimation;conceptually simple framework;bounding-box object detection;object mask;Faster R-CNN;called Mask R-CNN;high-quality segmentation mask;object instance segmentation;Feature extraction;Image segmentation;Object detection;Semantics;Quantization (signal);Robustness},
doi={10.1109/ICCV.2017.322},
ISSN={},
month={Oct},}
                  
@ARTICLE{Ren:2015:FRT:2969239.2969250,
author={S. {Ren} and K. {He} and R. {Girshick} and J. {Sun}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
year={2017},
volume={39},
number={6},
pages={1137-1149},
keywords={graphics processing units;neural nets;object detection;faster-R-CNN;real-time object detection;region proposal networks;RPN;full-image convolutional features;high-quality region proposals;attention mechanisms;deep VGG-16 model;GPU;object detection accuracy;PASCAL VOC 2007;PASCAL VOC 2012;MS COCO datasets;COCO 2015 competitions;ILSVRC;Proposals;Object detection;Convolutional codes;Feature extraction;Search problems;Detectors;Training;Object detection;region proposal;convolutional neural network},
doi={10.1109/TPAMI.2016.2577031},
ISSN={},
month={June},}
                  
                  
@Comment Faster-RCNN pytorch implementation
@article{jjfaster2rcnn,
    Author = {Jianwei Yang and Jiasen Lu and Dhruv Batra and Devi Parikh},
    Title = {A Faster Pytorch Implementation of Faster R-CNN},
    Journal = {https://github.com/jwyang/faster-rcnn.pytorch},
    Year = {2017}
}
                  
@Comment R-CNN                  
@INPROCEEDINGS{DBLP:journals/corr/GirshickDDM13,
author={R. {Girshick} and J. {Donahue} and T. {Darrell} and J. {Malik}},
booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},
title={Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
year={2014},
volume={},
number={},
pages={580-587},
keywords={image segmentation;neural nets;object detection;rich feature hierarchy;semantic segmentation;object detection performance;canonical PASCAL VOC dataset;low-level image feature;detection algorithm;mean average precision;mAP;high-capacity convolutional neural network;bottom-up region proposal;segment objects;labeled training data;supervised pretraining;auxiliary task;domain-specific fine-tuning;performance boost;R-CNN;image features;source code;Proposals;Feature extraction;Training;Visualization;Object detection;Vectors;Support vector machines},
doi={10.1109/CVPR.2014.81},
ISSN={},
month={June},}
                  
@Comment Fast-RCNN
@INPROCEEDINGS{Girshick:2015:FR:2919332.2920125,
author={R. {Girshick}},
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},
title={Fast R-CNN},
year={2015},
volume={},
number={},
pages={1440-1448},
keywords={feedforward neural nets;object detection;fast R-CNN;fast region-based convolutional network method;object detection;VGG16 network;Python;C++;Caffe;open-source MIT License;Training;Proposals;Feature extraction;Object detection;Pipelines;Computer architecture;Open source software},
doi={10.1109/ICCV.2015.169},
ISSN={},
month={Dec},}
 
@Comment YOLO                 
@INPROCEEDINGS{DBLP:journals/corr/RedmonDGF15,
author={J. {Redmon} and S. {Divvala} and R. {Girshick} and A. {Farhadi}},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={You Only Look Once: Unified, Real-Time Object Detection},
year={2016},
volume={},
number={},
pages={779-788},
keywords={image classification;image representation;neural nets;object detection;you only look once;unified real-time object detection;object classifiers;bounding boxes;class probabilities;neural network;detection pipeline;detection performance;YOLO model;object representation;DPM;R-CNN;natural images;Computer architecture;Microprocessors;Object detection;Training;Real-time systems;Neural networks;Pipelines},
doi={10.1109/CVPR.2016.91},
ISSN={},
month={June},}
                  
@Comment SIFT                  
@article{Lowe2004
,	author	= {Lowe, David G.}
,	journal	= {International Journal of Computer Vision}
,	month	= {nov}
,	number	= {2}
,	pages	= {91--110}
,	title	= {Distinctive Image Features from Scale-Invariant Keypoints}
,	volume	= {60}
,	year	= {2004}
}


@Comment HOG
@article{dalal2005histogramcvpr
,	author	= {Dalal, Navneet and Triggs, Bill}
,	title	= {Histograms of oriented gradients for human detection}
,	journal	= {CVPR}
,	year	= {2005}
}

@Comment optical flow
@incollection{dalal2006human
,	title	= {Human detection using oriented histograms of flow and appearance}
,	author	= {Dalal, Navneet and Triggs, Bill and Schmid, Cordelia}
,	booktitle	= {Computer Vision--ECCV 2006}
,	pages	= {428--441}
,	year	= {2006}
,	publisher	= {Springer}
}

@Comment 3D Convolution
@ARTICLE{pmid:22392705,
author={S. {Ji} and W. {Xu} and M. {Yang} and K. {Yu}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={3D Convolutional Neural Networks for Human Action Recognition},
year={2013},
volume={35},
number={1},
pages={221-231},
keywords={feature extraction;gesture recognition;image classification;image motion analysis;image representation;neural nets;spatiotemporal phenomena;video surveillance;3D convolutional neural networks;automated human action recognition;complex handcrafted features;deep model;3D CNN model;temporal dimensions;spatial dimensions;motion information encoding;feature representation;high-level features;airport surveillance videos;baseline methods;Three dimensional displays;Solid modeling;Feature extraction;Computer architecture;Videos;Kernel;Computational modeling;Deep learning;convolutional neural networks;3D convolution;model combination;action recognition;Algorithms;Decision Support Techniques;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Movement;Neural Networks (Computer);Pattern Recognition, Automated;Subtraction Technique},
doi={10.1109/TPAMI.2012.59},
ISSN={},
month={Jan},}
                  
@Comment 2 stream cnn -> classification
@inproceedings{simonyan2014two
,	title	= {Two-stream convolutional networks for action recognition in videos}
,	author	= {Simonyan, Karen and Zisserman, Andrew}
,	booktitle	= {Advances in Neural Information Processing Systems}
,	pages	= {568--576}
,	year	= {2014}
}



@Comment Finding action tubes
@INPROCEEDINGS{DBLP:journals/corr/GkioxariM14,
author={G. {Gkioxari} and J. {Malik}},
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Finding action tubes},
year={2015},
volume={},
number={},
pages={759-768},
keywords={feature extraction;image classification;image motion analysis;image representation;neural nets;object detection;shape recognition;video signal processing;action tubes;action detection;videos;object detection;2D images;action models;feature hierarchies;shape cues;kinematic cues;appearance;image region proposals;motion salient;spatio-temporal feature representations extraction;classifiers;convolutional neural networks;Videos;Feature extraction;Electron tubes;Support vector machines;Shape;Optical imaging;Training},
doi={10.1109/CVPR.2015.7298676},
ISSN={},
month={June},}
                  

@Comment ACT-detector                 
@INPROCEEDINGS{kalogeiton17iccv:hal-01519812,
author={V. {Kalogeiton} and P. {Weinzaepfel} and V. {Ferrari} and C. {Schmid}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Action Tubelet Detector for Spatio-Temporal Action Localization},
year={2017},
volume={},
number={},
pages={4415-4423},
keywords={convolution;feature extraction;image sequences;object detection;regression analysis;video signal processing;ACT-detector;action Tubelet detector;spatio-temporal action localization;anchor boxes;temporal stacking;object detectors;Detectors;Videos;Proposals;Feature extraction;Convolutional codes;Electron tubes;Shape},
doi={10.1109/ICCV.2017.472},
ISSN={},
month={Oct},}
                  
@Comment T-CNN                  
@INPROCEEDINGS{DBLP:journals/corr/HouCS17,
author={R. {Hou} and C. {Chen} and M. {Shah}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos},
year={2017},
volume={},
number={},
pages={5823-5832},
keywords={convolution;feature extraction;image classification;image motion analysis;image recognition;learning (artificial intelligence);neural nets;object detection;video signal processing;ConvNet;untrimmed videos;video datasets;spatio-temporal action detection;3D Convolutional Network features;Tube Convolutional Neural Network;end-to-end deep network;temporal feature;spatial feature;two-stream CNN framework;frame-level action proposal generation;video action detection approaches;video analysis;object detection;image classification;deep learning;T-CNN;Tube convolutional neural network;Videos;Proposals;Three-dimensional displays;Electron tubes;Feature extraction;Two dimensional displays;Machine learning},
doi={10.1109/ICCV.2017.620},
ISSN={},
month={Oct},}
                  
                  
@Comment Learning to track
@INPROCEEDINGS{DBLP:journals/corr/WeinzaepfelHS15,
author={P. {Weinzaepfel} and Z. {Harchaoui} and C. {Schmid}},
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},
title={Learning to Track for Spatio-Temporal Action Localization},
year={2015},
volume={},
number={},
pages={3164-3172},
keywords={image motion analysis;learning (artificial intelligence);visual databases;spatiotemporal action localization;realistic videos;frame-level;static features;motion CNN features;tracking-by-detection approach;instance-level detectors;class-level detectors;motion histogram;sliding-window approach;J-HMDB datasets;UCF-101 datasets;UCF-Sports datasets;Proposals;Tracking;Videos;Feature extraction;Detectors;Object detection;Optical imaging},
doi={10.1109/ICCV.2015.362},
ISSN={},
month={Dec},}

@Comment Multi-region two-stream R-CNN
@inproceedings{peng:hal-01349107,
  TITLE = {{Multi-region two-stream R-CNN for action detection}},
  AUTHOR = {Peng, Xiaojiang and Schmid, Cordelia},
  URL = {https://hal.inria.fr/hal-01349107},
  BOOKTITLE = {{ECCV - European Conference on Computer Vision}},
  ADDRESS = {Amsterdam, Netherlands},
  PUBLISHER = {{Springer}},
  SERIES = {Lecture Notes in Computer Science},
  VOLUME = {9908},
  PAGES = {744-759},
  YEAR = {2016},
  MONTH = Oct,
  DOI = {10.1007/978-3-319-46493-0\_45},
  KEYWORDS = {two stream R-CNN ; multi-region CNNs ; faster R-CNN ; Action detection},
  PDF = {https://hal.inria.fr/hal-01349107/file/eccv16-pxj-v3.pdf},
  HAL_ID = {hal-01349107},
  HAL_VERSION = {v3},
}
                  
@Comment Online Real time Multiple Spatiotemporal Action Localisation
@INPROCEEDINGS{singh2016online,
author={G. {Singh} and S. {Saha} and M. {Sapienza} and P. {Torr} and F. {Cuzzolin}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction},
year={2017},
volume={},
number={},
pages={3657-3666},
keywords={feature extraction;image classification;learning (artificial intelligence);object detection;video signal processing;real-time SSD;Single Shot MultiBox Detector;video frame;action tubes;SSD frame level detections;S/T detection;online S/T action localisation;online real-time multiple spatiotemporal action localisation;deep-learning framework;online algorithm;multiple spatiotemporal action classification;detection boxes classification;Real-time systems;Streaming media;Electron tubes;Proposals;Optical imaging;Detectors;Computer architecture},
doi={10.1109/ICCV.2017.393},
ISSN={},
month={Oct},}

@Comment FPN
@article{DBLP:journals/corr/LinDGHHB16,
  author    = {Tsung{-}Yi Lin and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick and
               Kaiming He and
               Bharath Hariharan and
               Serge J. Belongie},
  title     = {Feature Pyramid Networks for Object Detection},
  journal   = {CoRR},
  volume    = {abs/1612.03144},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.03144},
  archivePrefix = {arXiv},
  eprint    = {1612.03144},
  timestamp = {Mon, 13 Aug 2018 16:48:50 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LinDGHHB16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

                  

@Comment SSD                  
@article{DBLP:journals/corr/LiuAESR15,
  author    = {Wei Liu and
               Dragomir Anguelov and
               Dumitru Erhan and
               Christian Szegedy and
               Scott E. Reed and
               Cheng{-}Yang Fu and
               Alexander C. Berg},
  title     = {{SSD:} Single Shot MultiBox Detector},
  journal   = {CoRR},
  volume    = {abs/1512.02325},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.02325},
  archivePrefix = {arXiv},
  eprint    = {1512.02325},
  timestamp = {Mon, 13 Aug 2018 16:48:29 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LiuAESR15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Comment RNN progress
@article{DBLP:journals/corr/abs-1903-00304,
  author    = {Bo Hu and
               Jianfei Cai and
               Tat{-}Jen Cham and
               Junsong Yuan},
  title     = {Progress Regression {RNN} for Online Spatial-Temporal Action Localization
               in Unconstrained Videos},
  journal   = {CoRR},
  volume    = {abs/1903.00304},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.00304},
  archivePrefix = {arXiv},
  eprint    = {1903.00304},
  timestamp = {Sat, 30 Mar 2019 19:27:21 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-00304},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Comment Hara_2018_CVPR
@INPROCEEDINGS{hara3dcnns,
author={K. {Hara} and H. {Kataoka} and Y. {Satoh}},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
title={Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?},
year={2018},
volume={},
number={},
pages={6546-6555},
keywords={computer vision;convolutional neural nets;image motion analysis;spatiotemporal phenomena;stereo image processing;video signal processing;ImageNet;deep convolutional neural networks;spatiotemporal 3D CNN;2D CNN;video datasets;spatio-temporal 3D kernels;action recognition;ResNet-18 training;Kinetics dataset;Kinetics test set;UCF-101;HMDB-51;computer vision;Three-dimensional displays;Kinetic theory;Two dimensional displays;Training;Task analysis;Kernel;Computer vision},
doi={10.1109/CVPR.2018.00685},
ISSN={},
month={June},}
                  
@Comment 2D ResNet
@INPROCEEDINGS{DBLP:journals/corr/HeZRS15,
author={K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Deep Residual Learning for Image Recognition},
year={2016},
volume={},
number={},
pages={770-778},
keywords={image classification;learning (artificial intelligence);neural nets;object detection;COCO segmentation;ImageNet localization;ILSVRC & COCO 2015 competitions;deep residual nets;COCO object detection dataset;visual recognition tasks;CIFAR-10;ILSVRC 2015 classification task;ImageNet test set;VGG nets;residual nets;ImageNet dataset;residual function learning;deeper neural network training;image recognition;deep residual learning;Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
doi={10.1109/CVPR.2016.90},
ISSN={},
month={June},}
                  
@Comment Kinetics Dataset
@article{DBLP:journals/corr/KayCSZHVVGBNSZ17,
  author    = {Will Kay and
               Jo{\~{a}}o Carreira and
               Karen Simonyan and
               Brian Zhang and
               Chloe Hillier and
               Sudheendra Vijayanarasimhan and
               Fabio Viola and
               Tim Green and
               Trevor Back and
               Paul Natsev and
               Mustafa Suleyman and
               Andrew Zisserman},
  title     = {The Kinetics Human Action Video Dataset},
  journal   = {CoRR},
  volume    = {abs/1705.06950},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.06950},
  archivePrefix = {arXiv},
  eprint    = {1705.06950},
  timestamp = {Mon, 13 Aug 2018 16:46:23 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KayCSZHVVGBNSZ17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Comment T3D
@article{DBLP:journals/corr/abs-1711-08200,
  author    = {Ali Diba and
               Mohsen Fayyaz and
               Vivek Sharma and
               Amir Hossein Karami and
               Mohammad Mahdi Arzani and
               Rahman Yousefzadeh and
               Luc Van Gool},
  title     = {Temporal 3D ConvNets: New Architecture and Transfer Learning for Video
               Classification},
  journal   = {CoRR},
  volume    = {abs/1711.08200},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.08200},
  archivePrefix = {arXiv},
  eprint    = {1711.08200},
  timestamp = {Mon, 13 Aug 2018 16:48:57 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1711-08200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


                  
@article{Aggarwal:2011:HAA:1922649.1922653,
 author = {Aggarwal, J.K. and Ryoo, M.S.},
 title = {Human Activity Analysis: A Review},
 journal = {ACM Comput. Surv.},
 issue_date = {April 2011},
 volume = {43},
 number = {3},
 month = apr,
 year = {2011},
 issn = {0360-0300},
 pages = {16:1--16:43},
 articleno = {16},
 numpages = {43},
 url = {http://doi.acm.org/10.1145/1922649.1922653},
 doi = {10.1145/1922649.1922653},
 acmid = {1922653},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Computer vision, activity analysis, event detection, human activity recognition, video recognition},
} 

@Comment 2-steam FasterRCNN
@article{DBLP:journals/corr/SahaSSTC16,
  author    = {Suman Saha and
               Gurkirt Singh and
               Michael Sapienza and
               Philip H. S. Torr and
               Fabio Cuzzolin},
  title     = {Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos},
  journal   = {CoRR},
  volume    = {abs/1608.01529},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.01529},
  archivePrefix = {arXiv},
  eprint    = {1608.01529},
  timestamp = {Mon, 13 Aug 2018 16:46:29 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SahaSSTC16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}                  

@Comment 3D CNNS                  
@ARTICLE{6165309,
author={S. {Ji} and W. {Xu} and M. {Yang} and K. {Yu}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={3D Convolutional Neural Networks for Human Action Recognition},
year={2013},
volume={35},
number={1},
pages={221-231},
keywords={feature extraction;gesture recognition;image classification;image motion analysis;image representation;neural nets;spatiotemporal phenomena;video surveillance;3D convolutional neural networks;automated human action recognition;complex handcrafted features;deep model;3D CNN model;temporal dimensions;spatial dimensions;motion information encoding;feature representation;high-level features;airport surveillance videos;baseline methods;Three dimensional displays;Solid modeling;Feature extraction;Computer architecture;Videos;Kernel;Computational modeling;Deep learning;convolutional neural networks;3D convolution;model combination;action recognition;Algorithms;Decision Support Techniques;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Movement;Neural Networks (Computer);Pattern Recognition, Automated;Subtraction Technique},
doi={10.1109/TPAMI.2012.59},
ISSN={},
month={Jan},}
                  
                  
@Comment Action localization with tubelets from motion - Introduction of tubelets
@INPROCEEDINGS{6909495,
author={M. {Jain} and J. v. {Gemert} and H. {Jégou} and P. {Bouthemy} and C. G. M. {Snoek}},
booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},
title={Action Localization with Tubelets from Motion},
year={2014},
volume={},
number={},
pages={740-747},
keywords={image motion analysis;image sampling;image sequences;action localization;sampling strategy;2D+t sequences;bounding boxes;tubelets;image localization;super-voxel;action related motion;background motion;bounding box sequences;Videos;Merging;Histograms;Motion segmentation;Search problems;Image segmentation;Image color analysis},
doi={10.1109/CVPR.2014.100},
ISSN={},
month={June},}

@Comment Two-Stream Convolutional Networks for Action Recognition in Videos
@article{DBLP:journals/corr/SimonyanZ14,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Two-Stream Convolutional Networks for Action Recognition in Videos},
  journal   = {CoRR},
  volume    = {abs/1406.2199},
  year      = {2014},
  url       = {http://arxiv.org/abs/1406.2199},
  archivePrefix = {arXiv},
  eprint    = {1406.2199},
  timestamp = {Mon, 13 Aug 2018 16:47:39 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@Comment @Comment Rethinking the Faster R-CNN Architecture for Temporal Action Localization
@INPROCEEDINGS{Chao_2018_CVPR,
author={Y. {Chao} and S. {Vijayanarasimhan} and B. {Seybold} and D. A. {Ross} and J. {Deng} and R. {Sukthankar}},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
title={Rethinking the Faster R-CNN Architecture for Temporal Action Localization},
year={2018},
volume={},
number={},
pages={1130-1139},
keywords={computer vision;feature extraction;feedforward neural nets;gesture recognition;image classification;image colour analysis;image fusion;image motion analysis;image representation;learning (artificial intelligence);neural net architecture;object detection;video signal processing;action proposal;temporal action localization;receptive field alignment;multiscale architecture;action durations;proposal generation;action classification;multistream feature fusion;R-CNN architecture;RCNN object detection framework;TAL-Net;ActivityNet challenge;Proposals;Object detection;Feature extraction;Two dimensional displays;Microsoft Windows;Image segmentation;Computer architecture},
doi={10.1109/CVPR.2018.00124},
ISSN={},
month={June},}

@Comment 2 strean action localization                  
@INPROCEEDINGS{DBLP:journals/corr/abs-1802-08362,
author={B. {Zhang} and L. {Wang} and Z. {Wang} and Y. {Qiao} and H. {Wang}},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Real-Time Action Recognition with Enhanced Motion Vector CNNs},
year={2016},
volume={},
number={},
pages={2718-2726},
keywords={image recognition;image sequences;learning (artificial intelligence);motion estimation;neural nets;video coding;knowledge learning;recognition performance;video compression;optical flow calculation;video based action recognition;deep two-stream architecture;enhanced motion vector CNNs;real-time action recognition;Optical imaging;Real-time systems;Streaming media;Noise measurement;Training;Optical computing;Video compression},
doi={10.1109/CVPR.2016.297},
ISSN={},
month={June},}
                  
                  
@Comment Large-Scale Video Classification with Convolutional Neural Networks to prwto me cnn
@INPROCEEDINGS{6909619,
author={A. {Karpathy} and G. {Toderici} and S. {Shetty} and T. {Leung} and R. {Sukthankar} and L. {Fei-Fei}},
booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},
title={Large-Scale Video Classification with Convolutional Neural Networks},
year={2014},
volume={},
number={},
pages={1725-1732},
keywords={image classification;image motion analysis;multimedia computing;neural nets;social networking (online);spatiotemporal phenomena;video signal processing;video classification;convolutional neural networks;CNN;image recognition problems;YouTube videos;local spatiotemporal information;spatiotemporal networks;feature-based baselines;UCF-101 action recognition dataset;UCF-101 baseline model;Streaming media;Training;Computer architecture;Spatial resolution;Computational modeling;Feature extraction;convolutional;neural;network;video;classification;action;recognition;large-scale;dataset;sports},
doi={10.1109/CVPR.2014.223},
ISSN={},
month={June},}
                  
@Comment Convolutional Two-Stream Network Fusion for Video Action Recognition allo ena gia action recognition
@INPROCEEDINGS{DBLP:journals/corr/FeichtenhoferPZ16,
author={C. {Feichtenhofer} and A. {Pinz} and A. {Zisserman}},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Convolutional Two-Stream Network Fusion for Video Action Recognition},
year={2016},
volume={},
number={},
pages={1933-1941},
keywords={convolution;feature extraction;image motion analysis;neural nets;prediction theory;video signal processing;convolutional two-stream network fusion;video action recognition;convolutional neural networks;ConvNets;human action recognition;softmax layer;spatial network;temporal network;convolution layer;class prediction layer;abstract convolutional features;spatiotemporal neighbourhoods;ConvNet architecture;spatiotemporal fusion;video snippets;Fuses;Convolution;Spatiotemporal phenomena;Optical imaging;Two dimensional displays;Pattern recognition;Computer architecture},
doi={10.1109/CVPR.2016.213},
ISSN={},
month={June},}
                  
@Comment To prwto me LSTM
@ARTICLE{DBLP:journals/corr/DonahueHGRVSD14,
author={J. {Donahue} and L. A. {Hendricks} and M. {Rohrbach} and S. {Venugopalan} and S. {Guadarrama} and K. {Saenko} and T. {Darrell}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Long-Term Recurrent Convolutional Networks for Visual Recognition and Description},
year={2017},
volume={39},
number={4},
pages={677-691},
keywords={backpropagation;computer vision;image sequences;neural net architecture;object recognition;recurrent neural nets;long-term recurrent convolutional networks;visual recognition;visual description;recurrent convolutional architectures;large-scale visual understanding tasks;activity recognition;image captioning;video description;compositional representation learning;long-term dependency Learning;network state updates;differentiable recurrent models;variable-length input mapping;variable-length output mapping;complex temporal dynamics;backpropagation;recurrent sequence models;visual convolutional network models;temporal dynamic learning;convolutional perceptual representations;Visualization;Computational modeling;Computer architecture;Data models;Logic gates;Predictive models;Recurrent neural networks;Computer vision;convolutional nets;deep learning;transfer learning},
doi={10.1109/TPAMI.2016.2599174},
ISSN={},
month={April},}
                  
                  
@Comment Exei LSTM                  
@INPROCEEDINGS{DBLP:journals/corr/NgHVVMT15,
author={ {Joe Yue-Hei Ng} and M. {Hausknecht} and S. {Vijayanarasimhan} and O. {Vinyals} and R. {Monga} and G. {Toderici}},
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Beyond short snippets: Deep networks for video classification},
year={2015},
volume={},
number={},
pages={4694-4702},
keywords={image classification;image recognition;image segmentation;image sequences;neural nets;object detection;video signal processing;video classification;short snippets;convolutional neural networks;CNN;image recognition problems;deep neural network architectures;image information;full length videos;convolutional temporal feature pooling architectures;long short-term memory cells;LSTM;UCF-101 datasets;sports 1 million dataset;optical flow information;Optical imaging;Computer architecture;Logic gates;Training;Time-domain analysis;Neural networks;Image recognition},
doi={10.1109/CVPR.2015.7299101},
ISSN={},
month={June},}
                  
@Comment To trito                  
@article{DBLP:journals/corr/MaCKA17,
  author    = {Chih{-}Yao Ma and
               Min{-}Hung Chen and
               Zsolt Kira and
               Ghassan AlRegib},
  title     = {{TS-LSTM} and Temporal-Inception: Exploiting Spatiotemporal Dynamics
               for Activity Recognition},
  journal   = {CoRR},
  volume    = {abs/1703.10667},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.10667},
  archivePrefix = {arXiv},
  eprint    = {1703.10667},
  timestamp = {Mon, 13 Aug 2018 16:49:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MaCKA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Comment To paper tou TCN                  
@article{DBLP:journals/corr/abs-1803-01271,
  author    = {Shaojie Bai and
               J. Zico Kolter and
               Vladlen Koltun},
  title     = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks
               for Sequence Modeling},
  journal   = {CoRR},
  volume    = {abs/1803.01271},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.01271},
  archivePrefix = {arXiv},
  eprint    = {1803.01271},
  timestamp = {Mon, 13 Aug 2018 16:47:39 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1803-01271},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@Comment TSN - Temporal Segment Networks: Towards Good Practices for Deep Action Recognition - action recognition
@article{DBLP:journals/corr/WangXW0LTG16,
  author    = {Limin Wang and
               Yuanjun Xiong and
               Zhe Wang and
               Yu Qiao and
               Dahua Lin and
               Xiaoou Tang and
               Luc Van Gool},
  title     = {Temporal Segment Networks: Towards Good Practices for Deep Action
               Recognition},
  journal   = {CoRR},
  volume    = {abs/1608.00859},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.00859},
  archivePrefix = {arXiv},
  eprint    = {1608.00859},
  timestamp = {Wed, 11 Sep 2019 15:40:23 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/WangXW0LTG16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@Comment C3D
@INPROCEEDINGS{Tran2014LearningSF,
author={D. {Tran} and L. {Bourdev} and R. {Fergus} and L. {Torresani} and M. {Paluri}},
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},
title={Learning Spatiotemporal Features with 3D Convolutional Networks},
year={2015},
volume={},
number={},
pages={4489-4497},
keywords={feature extraction;image classification;learning (artificial intelligence);neural nets;spatiotemporal phenomena;video signal processing;spatiotemporal feature learning;3D convolutional networks;deep 3-dimensional convolutional networks;3D ConvNets;large scale supervised video dataset;homogeneous architecture;convolution kernels;C3D features;convolutional 3D;linear classifier;UCF101 dataset;Three-dimensional displays;Convolution;Kernel;Feature extraction;Solid modeling;Streaming media;Training},
doi={10.1109/ICCV.2015.510},
ISSN={},
month={Dec},}
                  
@Comment I3D                  
@INPROCEEDINGS{DBLP:journals/corr/CarreiraZ17,
author={J. {Carreira} and A. {Zisserman}},
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset},
year={2017},
volume={},
number={},
pages={4724-4733},
keywords={feature extraction;image classification;image motion analysis;image recognition;learning (artificial intelligence);spatiotemporal phenomena;video signal processing;action recognition;kinetics dataset;action classification;Two-Stream Inflated 3D ConvNet;successful ImageNet architecture designs;deep image classification ConvNets;Videos;Three-dimensional displays;Kinetic theory;Two dimensional displays;Kernel;Feature extraction;Solid modeling},
doi={10.1109/CVPR.2017.502},
ISSN={},
month={July},}

@Comment 3D ResNet firt paper                  
@INPROCEEDINGS{DBLP:journals/corr/abs-1708-07632,
author={K. {Hara} and H. {Kataoka} and Y. {Satoh}},
booktitle={2017 IEEE International Conference on Computer Vision Workshops (ICCVW)},
title={Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition},
year={2017},
volume={},
number={},
pages={3154-3160},
keywords={computer vision;convolution;feature extraction;feedforward neural nets;image classification;image motion analysis;image recognition;learning (artificial intelligence);object detection;object recognition;spatiotemporal phenomena;video databases;video signal processing;spatio-temporal features;residual networks;action recognition;convolutional neural networks;spatio-temporal 3D kernels;spatiotemporal features;videos;deep neural networks;2D-based CNNs;action representation;C3D;video databases;3D CNNs;Three-dimensional displays;Videos;Training;Kinetic theory;Kernel;Two dimensional displays;Databases},
doi={10.1109/ICCVW.2017.373},
ISSN={},
month={Oct},}
                  
                  
@Comment R(2+1)D
@INPROCEEDINGS{DBLP:journals/corr/abs-1711-11248,
author={D. {Tran} and H. {Wang} and L. {Torresani} and J. {Ray} and Y. {LeCun} and M. {Paluri}},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
title={A Closer Look at Spatiotemporal Convolutions for Action Recognition},
year={2018},
volume={},
number={},
pages={6450-6459},
keywords={convolution;feedforward neural nets;image filtering;image motion analysis;image recognition;learning (artificial intelligence);object recognition;video signal processing;spatiotemporal convolutions;action recognition;video analysis;3D convolutional filters;spatial components;temporal components;R(2+1)D spatiotemporal convolutional block;2D CNNs;residual learning;Three-dimensional displays;Two dimensional displays;Spatiotemporal phenomena;Solid modeling;Feature extraction;Computer architecture},
doi={10.1109/CVPR.2018.00675},
ISSN={},
month={June},}
                  
                  
@Comment 2D/3D Action Recognition
@INPROCEEDINGS{DBLP:journals/corr/abs-1802-09232,
author={D. C. {Luvizon} and D. {Picard} and H. {Tabia}},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
title={2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning},
year={2018},
volume={},
number={},
pages={5137-5146},
keywords={image motion analysis;image representation;image sequences;learning (artificial intelligence);pose estimation;2D-3D pose estimation;multitask deep learning;Penn Action;single architecture;video sequences;human action recognition;multitask framework;Pose estimation;Three-dimensional displays;Two dimensional displays;Visualization;Heating systems;Task analysis;Skeleton},
doi={10.1109/CVPR.2018.00539},
ISSN={},
month={June},}

@Comment human action recognition from skeleton sequences
@article{Luvizon_PRL_2017,
  author = "Diogo Carbonera Luvizon and Hedi Tabia and David Picard",
  title = "Learning features combination for human action recognition from skeleton sequences",
  journal = "Pattern Recognition Letters",
  volume = "99",
  pages = "13 - 20",
  year = "2017",
  doi = "https://doi.org/10.1016/j.patrec.2017.02.001",
}
                  
@Comment Recurrent Tubelet Proposal and Recognition Networks
@InProceedings{Li_2018_ECCV,
author = {Li, Dong and Qiu, Zhaofan and Dai, Qi and Yao, Ting and Mei, Tao},
title = {Recurrent Tubelet Proposal and Recognition Networks for Action Detection},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@Comment Dense-Net                  
@INPROCEEDINGS{DBLP:journals/corr/HuangLW16a,
author={G. {Huang} and Z. {Liu} and L. v. d. {Maaten} and K. Q. {Weinberger}},
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Densely Connected Convolutional Networks},
year={2017},
volume={},
number={},
pages={2261-2269},
keywords={convolution;feedforward neural nets;learning (artificial intelligence);DenseNet;traditional convolutional networks;feature propagation;feature reuse;object recognition benchmark tasks;dense convolutional network;vanishing-gradient problem;Training;Convolution;Network architecture;Convolutional codes;Neural networks;Road transportation},
doi={10.1109/CVPR.2017.243},
ISSN={},
month={July},}
                  

@Comment APO DW KAI PERA DEN EXW DIAVASEI
@ARTICLE{BobickAaron,
author={A. F. {Bobick} and J. W. {Davis}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={The recognition of human movement using temporal templates},
year={2001},
volume={23},
number={3},
pages={257-267},
keywords={computer vision;image sequences;image motion analysis;image reconstruction;human movement recognition;temporal templates;view-based approach;human movement representation;motion properties;aerobics exercises;recognition method;temporal segmentation;Image sequences;Image recognition;Computer Society;Computer vision;Cameras;Labeling;Image reconstruction;Humans;Pattern recognition;Pixel},
doi={10.1109/34.910878},
ISSN={},
month={March},}

@INPROCEEDINGS{1467296,
author={E. {Shechtman} and M. {Irani}},
booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
title={Space-time behavior based correlation},
year={2005},
volume={1},
number={},
pages={405-412 vol. 1},
keywords={image matching;image sequences;video signal processing;correlation theory;space-time behavior based correlation;intensity information;2D image correlation;3D space-time volume;video sequences;Motion estimation;Video sequences;Motion measurement;Image segmentation;Videoconference;Performance evaluation;Tracking;Volume measurement;Optical filters;Apertures},
doi={10.1109/CVPR.2005.328},
ISSN={},
month={June},}

@INPROCEEDINGS{4270510,
author={Y. {Ke} and R. {Sukthankar} and M. {Hebert}},
booktitle={2007 IEEE Conference on Computer Vision and Pattern Recognition},
title={Spatio-temporal Shape and Flow Correlation for Action Recognition},
year={2007},
volume={},
number={},
pages={1-8},
keywords={correlation methods;feature extraction;gesture recognition;image classification;image segmentation;spatiotemporal phenomena;video signal processing;action recognition;spatiotemporal shape;flow-based correlation technique;video classification;video segmentation;object segmentation;feature extraction;tennis video;Shape;Cameras;Robustness;Image motion analysis;Image recognition;Humans;Computer science;Object segmentation;Object recognition;Image analysis},
doi={10.1109/CVPR.2007.383512},
ISSN={},
month={June},}

@INPROCEEDINGS{4587727,
author={M. D. {Rodriguez} and J. {Ahmed} and M. {Shah}},
booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition},
title={Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition},
year={2008},
volume={},
number={},
pages={1-8},
keywords={Fourier transforms;frequency-domain analysis;image recognition;action MACH;spatio-temporal maximum average correlation height filter;action recognition;template-based method;intra-class variability;3D spatiotemporal volume;frequency domain;Clifford Fourier transform;annotated human action datasets;Humans;Image motion analysis;Data analysis;Fourier transforms;Optical films;Optical filters;Computer vision;Spatiotemporal phenomena;Frequency domain analysis;Computational efficiency},
doi={10.1109/CVPR.2008.4587727},
ISSN={},
month={June},}

@INPROCEEDINGS{1541250,
author={Y. {Sheikh} and M. {Sheikh} and M. {Shah}},
booktitle={Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
title={Exploring the space of a human action},
year={2005},
volume={1},
number={},
pages={144-149 Vol. 1},
keywords={image recognition;image motion analysis;statistical analysis;human action recognition;execution rate;actor anthropometry;spatio-temporal space;image measurement;principal angle;statistical fluctuation;image recognition;Space exploration;Humans;Cameras;Computer vision;Anthropometry;Object recognition;Laboratories;Computer science;Linear approximation;Image recognition},
doi={10.1109/ICCV.2005.90},
ISSN={},
month={Oct},}

@INPROCEEDINGS{1541251,
author={A. {Yilmaz} and M. {Shah}},
booktitle={Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
title={Recognizing human actions in videos acquired by uncalibrated moving cameras},
year={2005},
volume={1},
number={},
pages={150-157 Vol. 1},
keywords={computational geometry;image motion analysis;object recognition;video cameras;video signal processing;dynamic scene geometry;multiview geometry;camera motion;uncalibrated moving camera;video image;human action recognition;Humans;Videos;Cameras;Geometry;Computer science;Layout;Image motion analysis;Optical computing;Surveillance;Content based retrieval},
doi={10.1109/ICCV.2005.201},
ISSN={},
month={Oct},}

@INPROCEEDINGS{784616,
author={O. {Chomat} and J. L. {Crowley}},
booktitle={Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)},
title={Probabilistic recognition of activity using local appearance},
year={1999},
volume={2},
number={},
pages={104-109 Vol. 2},
keywords={gesture recognition;augmented reality;motion estimation;image recognition;probabilistic recognition;joint probability density functions;spatio-temporal receptive fields;hand gestures;augmented reality;Statistics;Histograms;Filters;Character recognition;Probability density function;Robustness;Lighting;Pattern recognition;Legged locomotion;Augmented reality},
doi={10.1109/CVPR.1999.784616},
ISSN={},
month={June},}

@INPROCEEDINGS{990935,
author={L. {Zelnik-Manor} and M. {Irani}},
booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
title={Event-based analysis of video},
year={2001},
volume={2},
number={},
pages={II-II},
keywords={image sequences;video signal processing;image segmentation;pattern clustering;indexing;event-based analysis;dynamic events;long-term temporal objects;spatio-temporal features;multiple temporal scales;statistical distance measure;behavioral content;event clustering;event isolation;long continuous video sequences;temporal segmentation;event-consistent sub-sequences;event-consistent clusters;event-based indexing;example clips;Video sequences;Motion pictures;Length measurement;Dynamic range;Indexing;Information analysis;Parametric statistics;Stochastic processes;Computer science;Event detection},
doi={10.1109/CVPR.2001.990935},
ISSN={},
month={Dec},}

@INPROCEEDINGS{1544882,
author={M. {Blank} and L. {Gorelick} and E. {Shechtman} and M. {Irani} and R. {Basri}},
booktitle={Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
title={Actions as space-time shapes},
year={2005},
volume={2},
number={},
pages={1395-1402 Vol. 2},
keywords={feature extraction;image motion analysis;image sequences;Poisson equation;space-time shapes;video sequences;space-time volume;volumetric space-time action shapes;Poisson equation;space-time feature extraction;local space-time saliency;action dynamics;shape structure;shape orientation;action recognition;action detection;video alignment;partial occlusions;2D shape analysis;Shape;Humans;Video sequences;Torso;Poisson equations;Computer vision;Information analysis;Optical computing;Image motion analysis;Motion analysis},
doi={10.1109/ICCV.2005.28},
ISSN={},
month={Oct},}

@INPROCEEDINGS{1238378,
author={ {Laptev} and {Lindeberg}},
booktitle={Proceedings Ninth IEEE International Conference on Computer Vision},
title={Space-time interest points},
year={2003},
volume={},
number={},
pages={432-439 vol.1},
keywords={image motion analysis;image representation;spatiotemporal phenomena;computer vision;feature extraction;image pattern representation;spatial interest point;spatio-temporal domain;video data representation;spatio-temporal event detection;scale-invariant spatio-temporal descriptor;human motion analysis;Event detection;Computer vision;Image motion analysis;Motion analysis;Layout;Indexing;Optical computing;Spatiotemporal phenomena;Acceleration;Videoconference},
doi={10.1109/ICCV.2003.1238378},
ISSN={},
month={Oct},}

@INPROCEEDINGS{1570899,
author={P. {Dollar} and V. {Rabaud} and G. {Cottrell} and S. {Belongie}},
booktitle={2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance},
title={Behavior recognition via sparse spatio-temporal features},
year={2005},
volume={},
number={},
pages={65-72},
keywords={image recognition;object detection;behavior recognition;spatio-temporal features;object recognition;Object recognition;Object detection;Detectors;Mice;Computer vision;Robustness;Spatiotemporal phenomena;Video sequences;Prototypes;Computer science},
doi={10.1109/VSPETS.2005.1570899},
ISSN={},
month={Oct},}

@inproceedings{Niebles,
author = {Niebles, Juan Carlos and Wang, Hongcheng and Li, Fei Fei},
year = {2006},
month = {09},
pages = {1249-1258},
title = {Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words.},
volume = {79},
journal = {International Journal of Computer Vision}
}
                  
@INPROCEEDINGS{1467373,
author={ {Alper Yilmaz} and {Mubarak Shah}},
booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
title={Actions sketch: a novel action representation},
year={2005},
volume={1},
number={},
pages={984-989 vol. 1},
keywords={object recognition;motion estimation;image sequences;graph theory;computational geometry;action sketch;action representation;3D object;2D contour;spatiotemporal volume;differential geometric surface property;action descriptor;point correspondence problem;graph theory;action recognition;Shape;Legged locomotion;Spatiotemporal phenomena;Humans;Computer vision;Hidden Markov models;Data mining;Trajectory;Computer science;Surface treatment},
doi={10.1109/CVPR.2005.58},
ISSN={},
month={June},}

@INPROCEEDINGS{Ryoo2006,
author={M. S. {Ryoo} and J. K. {Aggarwal}},
booktitle={18th International Conference on Pattern Recognition (ICPR'06)},
title={Semantic Understanding of Continued and Recursive Human Activities},
year={2006},
volume={1},
number={},
pages={379-378},
keywords={computer vision;context-free grammars;gesture recognition;image representation;semantic understanding;recursive human activities;context-free grammar based representation;high-level interactions;fighting;greeting;semantic descriptions;computer vision;Humans;Computer vision;Logic;Punching;Application software;Surveillance;Airports;Patient monitoring;Computerized monitoring;Senior citizens},
doi={10.1109/ICPR.2006.1043},
ISSN={},
month={Aug},}
                  
@Comment Action Classification
@InProceedings{Guo_2018_ECCV,
author = {Guo, Michelle and Chou, Edward and Huang, De-An and Song, Shuran and Yeung, Serena and Fei-Fei, Li},
title = {Neural Graph Matching Networks for Fewshot 3D Action Recognition},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@inproceedings{DBLP:DibaFSKAYG18,
  author    = {Ali Diba and
               Mohsen Fayyaz and
               Vivek Sharma and
               Amir Hossein Karami and
               Mohammad Mahdi Arzani and
               Rahman Yousefzadeh and
               Luc Van Gool},
  title     = {Temporal 3D ConvNets Using Temporal Transition Layer},
  booktitle = {2018 {IEEE} Conference on Computer Vision and Pattern Recognition
               Workshops, {CVPR} Workshops 2018, Salt Lake City, UT, USA, June 18-22,
               2018},
  pages     = {1117--1121},
  year      = {2018},
  url       = {http://openaccess.thecvf.com/content\_cvpr\_2018\_workshops/w19/html/Diba\_Temporal\_3D\_ConvNets\_CVPR\_2018\_paper.html},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/cvpr/DibaFSKAYG18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1711-01467,
  author    = {Rohit Girdhar and
               Deva Ramanan},
  title     = {Attentional Pooling for Action Recognition},
  journal   = {CoRR},
  volume    = {abs/1711.01467},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.01467},
  archivePrefix = {arXiv},
  eprint    = {1711.01467},
  timestamp = {Mon, 13 Aug 2018 16:48:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1711-01467},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{DBLP:journals/corr/ZhuLNH17a,
  author    = {Yi Zhu and
               Zhen{-}Zhong Lan and
               Shawn D. Newsam and
               Alexander G. Hauptmann},
  title     = {Hidden Two-Stream Convolutional Networks for Action Recognition},
  journal   = {CoRR},
  volume    = {abs/1704.00389},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.00389},
  archivePrefix = {arXiv},
  eprint    = {1704.00389},
  timestamp = {Thu, 25 Jul 2019 16:32:57 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhuLNH17a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/ZhangWWQW16,
  author    = {Bowen Zhang and
               Limin Wang and
               Zhe Wang and
               Yu Qiao and
               Hanli Wang},
  title     = {Real-time Action Recognition with Enhanced Motion Vector CNNs},
  journal   = {CoRR},
  volume    = {abs/1604.07669},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.07669},
  archivePrefix = {arXiv},
  eprint    = {1604.07669},
  timestamp = {Wed, 11 Sep 2019 15:40:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhangWWQW16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{7298735,
author={G. {Yu} and J. {Yuan}},
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition},
title={Fast action proposals for human action detection and search},
year={2015},
volume={},
number={},
pages={1302-1311},
keywords={image motion analysis;video signal processing;fast action proposals;human action detection;unconstrained videos;temporal series;spatial bounding boxes;spatiotemporal paths;action proposal generation;maximum set coverage problem;greedy search;MSRII;UCF 101;Proposals;Videos;Trajectory;Feature extraction;Electron tubes;Search problems;Computational efficiency},
doi={10.1109/CVPR.2015.7298735},
ISSN={},
month={June},}

@INPROCEEDINGS{7410732,
author={K. {Soomro} and H. {Idrees} and M. {Shah}},
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},
title={Action Localization in Videos through Context Walk},
year={2015},
volume={},
number={},
pages={3280-3288},
keywords={estimation theory;image segmentation;learning (artificial intelligence);probability;support vector machines;video signal processing;action localization;context walk;contextual relation learning;video regions;video over-segmentation;complexity reduction;action boundary preservation;supervoxel selection;probability estimation;conditional random field;SVM;support vector machines;Videos;Context;Training;Testing;Proposals;Electron tubes;Support vector machines},
doi={10.1109/ICCV.2015.375},
ISSN={},
month={Dec},}

@INPROCEEDINGS{6619185,
author={Y. {Tian} and R. {Sukthankar} and M. {Shah}},
booktitle={2013 IEEE Conference on Computer Vision and Pattern Recognition},
title={Spatiotemporal Deformable Part Models for Action Detection},
year={2013},
volume={},
number={},
pages={2642-2649},
keywords={gesture recognition;object detection;video signal processing;spatiotemporal deformable part models;action detection;object detection;image datasets;2D images;3D spatiotemporal volumes;intra-class variation;video datasets;spatiotemporal DPM;action classification;action localization;Spatiotemporal phenomena;Feature extraction;Deformable models;Computational modeling;Training;Three-dimensional displays;Solid modeling},
doi={10.1109/CVPR.2013.341},
ISSN={},
month={June},}

@inproceedings{Oneata,
author = {Oneata, Dan and Revaud, Jerome and Verbeek, Jakob and Schmid, Cordelia},
year = {2014},
month = {09},
pages = {},
title = {Spatio-Temporal Object Detection Proposals},
doi = {10.1007/978-3-319-10578-9_48}
}


@inproceedings{BMVC2015_177,
	title={APT: Action localization proposals from dense trajectories},
	author={Jan C. van Gemert and Mihir Jain and Ella Gati and Cees G. M. Snoek},
	year={2015},
	month={September},
	pages={177.1-177.12},
	articleno={177},
	numpages={12},
	booktitle={Proceedings of the British Machine Vision Conference (BMVC)},
	publisher={BMVA Press},

	doi={10.5244/C.29.177},
	isbn={1-901725-53-7},
	url={https://dx.doi.org/10.5244/C.29.177}
}

@INPROCEEDINGS{7410734,
author={W. {Chen} and J. J. {Corso}},
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},
title={Action Detection by Implicit Intentional Motion Clustering},
year={2015},
volume={},
number={},
pages={3298-3306},
keywords={feature extraction;graph theory;image motion analysis;pattern clustering;trajectory graph;spatiotemporal trajectory clustering;intentional movement extraction;intentional motion clustering;action detection;Trajectory;Proposals;Spatiotemporal phenomena;Benchmark testing;Computer vision;Tracking},
doi={10.1109/ICCV.2015.377},
ISSN={},
month={Dec},}


@article{DBLP:journals/corr/MettesGS16,
  author    = {Pascal Mettes and
               Jan C. van Gemert and
               Cees G. M. Snoek},
  title     = {Spot On: Action Localization from Pointly-Supervised Proposals},
  journal   = {CoRR},
  volume    = {abs/1604.07602},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.07602},
  archivePrefix = {arXiv},
  eprint    = {1604.07602},
  timestamp = {Mon, 13 Aug 2018 16:46:56 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MettesGS16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/BehlSSSCT17,
  author    = {Harkirat S. Behl and
               Michael Sapienza and
               Gurkirt Singh and
               Suman Saha and
               Fabio Cuzzolin and
               Philip H. S. Torr},
  title     = {Incremental Tube Construction for Human Action Detection},
  journal   = {CoRR},
  volume    = {abs/1704.01358},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.01358},
  archivePrefix = {arXiv},
  eprint    = {1704.01358},
  timestamp = {Mon, 13 Aug 2018 16:47:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/BehlSSSCT17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{DBLP:journals/corr/HeIDM17,
author={J. {He} and Z. {Deng} and M. S. {Ibrahim} and G. {Mori}},
booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
title={Generic Tubelet Proposals for Action Localization},
year={2018},
volume={},
number={},
pages={343-351},
keywords={image classification;image motion analysis;object detection;video signal processing;action localization;video-level tubelet proposals;video analysis tasks;unified temporal deep network;action classification;generic tubelet proposal method;class-independent TPN;tubelet generation methods;tube proposal network;TPN;L1 loss function;UCF-101 dataset;UCF-Sports dataset;J-HMDB21 dataset;Proposals;Videos;Electron tubes;Object detection;Task analysis;Trajectory;Standards},
doi={10.1109/WACV.2018.00044},
ISSN={},
month={March},}
                  

@INPROCEEDINGS{DBLP:journals/corr/SahaSC17,
author={S. {Saha} and G. {Singh} and F. {Cuzzolin}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture},
year={2017},
volume={},
number={},
pages={4424-4433},
keywords={convolution;feature extraction;image classification;image motion analysis;image recognition;image representation;learning (artificial intelligence);neural nets;object detection;optimisation;stereo image processing;video signal processing;video frames;AMTnet;3D region proposal classification;temporal encoding;complete action tubes;microtubes;test time the network;classification;action localisation;expensive flow maps;3D-RPN net;classical region proposal networks;deep net framework;action detection problem;video subsets;deep network architecture;post-processing step;frame-level detections;end-to-end trainable deep architecture;action-microtube regression;Proposals;Three-dimensional displays;Training;Electron tubes;Computer architecture;Encoding;Optical fiber networks},
doi={10.1109/ICCV.2017.473},
ISSN={},
month={Oct},}
                  

@INPROCEEDINGS{8237881,
author={H. {Zhu} and R. {Vial} and S. {Lu}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={TORNADO: A Spatio-Temporal Convolutional Regression Network for Video Action Proposal},
year={2017},
volume={},
number={},
pages={5814-5822},
keywords={convolution;image motion analysis;object detection;recurrent neural nets;regression analysis;video signal processing;TORNADO;spatio-temporal Convolutional regression network;video action proposal;video clip;spatio-temporal tubes;long-term recurrent convolutional network;object detection;action recognition;local temporal dynamics;human action proposal detection;regression-based detector;Convolutional LSTM;action boxes;Proposals;Detectors;Dynamic programming;Logic gates;Tornadoes;Electron tubes},
doi={10.1109/ICCV.2017.619},
ISSN={},
month={Oct},}

@INPROCEEDINGS{DBLP:journals/corr/ZolfaghariOSB17,
author={M. {Zolfaghari} and G. L. {Oliveira} and N. {Sedaghat} and T. {Brox}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection},
year={2017},
volume={},
number={},
pages={2923-2932},
keywords={image classification;image motion analysis;image sequences;Markov processes;pose estimation;spatiotemporal phenomena;video signal processing;chained multistream networks;human action recognition;visual cues;action classification performance;HMDB51 dataset;J-HMDB dataset;NTU RGB+D dataset;UCF101 dataset;temporal action localization;spatial action localization;Markov chain model;raw images;Videos;Computer architecture;Optical imaging;Image segmentation;Markov processes;Training},
doi={10.1109/ICCV.2017.316},
ISSN={},
month={Oct},}

@INPROCEEDINGS{DBLP:journals/corr/MettesS17,
author={P. {Mettes} and C. G. M. {Snoek}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Spatial-Aware Object Embeddings for Zero-Shot Localization and Classification of Actions},
year={2017},
volume={},
number={},
pages={4453-4462},
keywords={image classification;image motion analysis;object detection;object recognition;video signal processing;spatial awareness;object detectors;word embedding space;object positions;spatial-aware embedding;classification experiments;zero-shot localization;classification settings;human actions;global attribute;spatial-aware object embedding;action video datasets;spatial preferences;object awareness;spatiotemporal action retrieval;supervised action localization;spatial-aware object embeddings;actor-object interaction;action classification;Electron tubes;Proposals;Detectors;Training;Semantics;Sports equipment;Trajectory},
doi={10.1109/ICCV.2017.476},
ISSN={},
month={Oct},}
                  

@INPROCEEDINGS{8237344,
author={K. {Soomro} and M. {Shah}},
booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
title={Unsupervised Action Discovery and Localization in Videos},
year={2017},
volume={},
number={},
pages={696-705},
keywords={directed graphs;feature extraction;image classification;image segmentation;knapsack problems;pattern clustering;support vector machines;unsupervised learning;video signal processing;video features;undirected graph;classifier training;directed graph;knapsack optimization;SVM action classifiers;over-segmenting videos;automatic spatio-temporal annotations;unlabeled training videos;spectral clustering;bounding box annotations;unsupervised action localization;unsupervised action discovery;Videos;Training;Support vector machines;Optimization;Feature extraction;Clustering algorithms;Computer vision},
doi={10.1109/ICCV.2017.82},
ISSN={},
month={Oct},}

@article{DBLP:journals/corr/WeinzaepfelMS16,
  author    = {Philippe Weinzaepfel and
               Xavier Martin and
               Cordelia Schmid},
  title     = {Towards Weakly-Supervised Action Localization},
  journal   = {CoRR},
  volume    = {abs/1605.05197},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.05197},
  archivePrefix = {arXiv},
  eprint    = {1605.05197},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/WeinzaepfelMS16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1807-10066,
  author    = {Rohit Girdhar and
               Jo{\~{a}}o Carreira and
               Carl Doersch and
               Andrew Zisserman},
  title     = {A Better Baseline for {AVA}},
  journal   = {CoRR},
  volume    = {abs/1807.10066},
  year      = {2018},
  url       = {http://arxiv.org/abs/1807.10066},
  archivePrefix = {arXiv},
  eprint    = {1807.10066},
  timestamp = {Mon, 13 Aug 2018 16:48:03 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1807-10066},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{5255236,
author={P. F. {Felzenszwalb} and R. B. {Girshick} and D. {McAllester} and D. {Ramanan}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Object Detection with Discriminatively Trained Part-Based Models},
year={2010},
volume={32},
number={9},
pages={1627-1645},
keywords={data mining;iterative methods;object detection;object recognition;support vector machines;object detection system;discriminative trained part-based models;multiscale deformable part models;PASCAL object detection;margin-sensitive approach;data mining;latent SVM objective function;iterative training algorithm;object recognition;support vector machine;Object detection;Deformable models;Support vector machines;Bicycles;Computer vision;Shape;Speech recognition;Computer Society;Iterative algorithms;Lighting;Object recognition;deformable models;pictorial structures;discriminative training;latent SVM.;Algorithms;Artificial Intelligence;Discriminant Analysis;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity},
doi={10.1109/TPAMI.2009.167},
ISSN={},
month={Sep.},}

@Comment selective search
@ARTICLE{Uijlings13,
  author = {J.R.R. Uijlings and K.E.A. van de Sande and T. Gevers and A.W.M.
	Smeulders},
  title = {Selective Search for Object Recognition},
  journal = {International Journal of Computer Vision},
  year = {2013},
  doi = {10.1007/s11263-013-0620-5},
  owner = {jrruijli},
  timestamp = {2013.02.06},
  url = {http://www.huppelen.nl/publications/selectiveSearchDraft.pdf}
}

@INPROCEEDINGS{Manen:2013:POP:2586117.2587333,
author={S. {Manen} and M. {Guillaumin} and L. V. {Gool}},
booktitle={2013 IEEE International Conference on Computer Vision},
title={Prime Object Proposals with Randomized Prim's Algorithm},
year={2013},
volume={},
number={},
pages={2536-2543},
keywords={learning (artificial intelligence);object detection;trees (mathematics);SUN2012 benchmark datasets;PASCAL VOC 2012;PASCAL VOC 2007;randomization;object localizations;random partial spanning trees;image superpixels;connectivity graph;object discovery;object detectors;supervised learning;class-specific object detection;generic object detection;randomized Prim algorithm;prime object proposals;Proposals;Object detection;Image edge detection;Image color analysis;Image segmentation;Heuristic algorithms;Algorithm design and analysis;Object Detection;Object Proposal},
doi={10.1109/ICCV.2013.315},
ISSN={},
month={Dec},}

@ARTICLE{7420739,
author={R. G. {Cinbis} and J. {Verbeek} and C. {Schmid}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Weakly Supervised Object Localization with Multi-Fold Multiple Instance Learning},
year={2016},
volume={39},
number={1},
pages={189-203},
keywords={computer vision;learning (artificial intelligence);neural nets;object detection;time-consuming annotation process;weakly supervised learning;supervised information;object instances;multiple-instance learning approach;positive training images;multifold multiple instance learning procedure;erroneous object locations;localization accuracy;object category localization;computer vision;standard supervised training;box annotations;weakly supervised object localization;high-dimensional representations;Fisher vectors;convolutional neural network features;Training;Supervised learning;Computational efficiency;Iterative methods;Learning systems;Object detection;Visualization;Weakly supervised learning;object detection},
doi={10.1109/TPAMI.2016.2535231},
ISSN={},
month={Jan},}

@INPROCEEDINGS{DBLP:journals/corr/GuSVPRTLRSSM17,
author={C. {Gu} and C. {Sun} and D. A. {Ross} and C. {Vondrick} and C. {Pantofaru} and Y. {Li} and S. {Vijayanarasimhan} and G. {Toderici} and S. {Ricco} and R. {Sukthankar} and C. {Schmid} and J. {Malik}},
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
title={AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions},
year={2018},
volume={},
number={},
pages={6047-6056},
keywords={image motion analysis;video signal processing;video dataset;AVA dataset;composite actions;atomic actions;action representations;spatio-temporal action recognition;action complexity;action localization;video clips;spatio-temporally localized atomic visual actions;spatio-temporal annotations;Motion pictures;Visualization;Vocabulary;Sports;YouTube;Labeling;Detectors},
doi={10.1109/CVPR.2018.00633},
ISSN={},
month={June},}
                  
@INPROCEEDINGS{8099589,
author={T. {Lin} and P. {Dollár} and R. {Girshick} and K. {He} and B. {Hariharan} and S. {Belongie}},
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Feature Pyramid Networks for Object Detection},
year={2017},
volume={},
number={},
pages={936-944},
keywords={feature extraction;image representation;neural nets;object detection;object recognition;deep convolutional networks;pyramidal hierarchy;high-level semantic feature maps;Feature Pyramid Network;generic feature extractor;basic Faster R-CNN system;COCO detection benchmark;multiscale object detection;pyramid representations;FPN;Feature extraction;Detectors;Semantics;Computer architecture;Proposals;Object detection;Robustness},
doi={10.1109/CVPR.2017.106},
ISSN={},
month={July},}
