\documentclass{report}

\usepackage[ english, greek]{babel}
\usepackage[utf8]{inputenc}
\usepackage[LGR, T1]{fontenc}

% % 

\newcommand{\tl}{\textlatin}
\newcommand{\en}{\selectlanguage{english}}
\newcommand{\gr}{\selectlanguage{greek}}

\usepackage{hyperref}  % package for linking figures etc
\usepackage{enumitem}  % package for description with bullets
\usepackage{graphicx}  % package for importing images
\usepackage{mathtools} % package for math equation
\usepackage{mathrsfs}  % package for math font
\usepackage{indentfirst} % package for getting ident after section or paragraph
\usepackage{subcaption} % package for subfigures
\usepackage[export]{adjustbox}
\usepackage{longtable} % package for multi pages tables
\usepackage{multirow}  % package for tables, multirow
\usepackage{amssymb}
\usepackage{esvect}
\usepackage[
backend=bibtex,
citestyle=authoryear,
% citestyle=authoryear-comp,
% citestyle=authoryear-ibid,
bibstyle=numeric,
sorting=ynt,
% style=numeric,
% style=alphabetic ,
]{biblatex}
\addbibresource{References}

\graphicspath{ {./theory/figures/} }       % path for images

\begin{document}
\gr 
 
\chapter{\en Classification stage\gr }
Στα προηγούμενα 2 κεφάλαια παρουσιάσαμε την διαδικασία που χρησιμοποιούμε για να δημιουργήσουμε
υποψήφια \en action tubes\gr,  τα οποία πιθανώς να περιέχουν κάποια πραγματοποιούμενη δράση ή μπορεί όχι.
Τις περισσότερες φορές τα προτεινόμενα \en action tubes \gr ανήκουν στο φόντο, και γι' αυτό, όπως αναφέρθηκε
και στον προηγούμενο κεφάλαιο, είναι σημαντικό να επιλέξουμε έναν καλό αλγόριθμο που προτείνει καλές ακολουθίες
από πλαίσια. Ωστόσο, είναι αρκετά σημαντικό να επιλέξουμε και τον κατάλληλο ταξινομητή ο οποίος θα είναι σε θέση
με μεγάλη ακρίβεια να προβλέψει αν ένα υποψήφιο \en action tube \gr ανήκει σε μια γνωστή κατηγορία από δράσεις ή
ανήκει στο φόντο. Κι αυτό γιατί μπορεί να παράγουμε καλές προτάσεις για υποψήφιες δράσεις, αλλά αν ο ταξινομητής μας
δεν λειτουργεί στο έπακρο, το σύστημα μας πάλι θα αποτυγχάνει να αναγνωρίσει τις δράσεις. \par
Η σωστή επιλογή ενός ταξινομητή είναι μια μεγάλη απόφαση που καλούμαστε να πάρουμε. Ωστόσο,  αυτός ο ταξινομητής θα δεχθεί
ορισμένους χάρτες ενεργοποίησης τους οποίους θα κληθεί να ταξινομήσει. Συνεπώς, εκτός από την καλή επιλογή ταξινομητή, εξίσου
σημαντική είναι η καλή επιλογή χαρακτηριστικών. Τέλος, μεγάλο ρόλο παίζει και η διαδικασία εκπαίδευσης του ταξινομητή προκειμένου
να είναι σε θέση να γενικεύει και καταστάσεις \en overfitting \gr να αποφεύγονται. \par
Σε αυτό το κεφάλαιο παρουσιάζουμε διάφορες μεθόδους που χρησιμοποιήσαμε οι οποίες περιλαμβάνουν ένα Γραμμικό ταξινομητή, ένα \en
Recursive Neural Network (RNN)\gr, ένα \en Support Vector Machine (SVM)\gr και ένα \en Multilayer Perceptron(MLP)\gr. Επίσης,
πειραματιζόμαστε χρησιμοποιώντας χάρτες χαρακτηριστικών που εξηχθησαν μέσω του \en 3D RoiAlign \gr χρησιμοποιώντας παράλληλα
\en avg  \gr ή  \en max  pooling\gr. Τελευταίο αλλά εξίσου σημαντικό είναι το γεγονός ότι προσπαθήσαμε να βρούμε το καλύτερο
ποσοστό μεταξύ \en actio tubes \gr προσκηνίου και φόντο αλλά και τον συνολικό αριθμό τους που είναι απαραίτητα  κατά την διάρκεια της εκπαίδευσης προκειμένου ο ταξινομητής να λειτουργεί αποδοτικά. \par
Η όλη διαδικασία ταξινόμησης αποτελείται από τα ακόλουθα βήματα:
\begin{enumerate}
\item Διαχωρίζουμε το βίντεο σε μικρά βίντεο κλιπ και τροφοδοτούμε το δίκτυο \en  TPN \gr με αυτά τα βίντεο κλιπ
  και παίρνουμε ως αποτέλεσμα \tl{k}-προτεινόμενα \en ToIs \gr και τα αντίστοιχα χαρακτηριστικά τους για
  κάθε κλιπ βίντεο.
\item Συνδέουμε τα προτεινόμενα \en ToIs \gr για να πάρουμε \en action tubes \gr που μπορεί να περιέχουν
  μια ενέργεια.
\item Για κάθε υποψήφιο \en action tube\gr, η οποία είναι μια ακολουθία του ToIs,
  τροφοδοτούμε τους χάρτης ενεργοποίησης του στον ταξινομητή για ταξινόμηση.
\end{enumerate}
Στα πρώτα βήματα του σταδίου ταξινόμησης αναφερόμαστε μόνο στο σύνολο δεδομένων \en JHMDB\gr, επειδή έχει μικρότερο αριθμό βίντεο από το σύνολο δεδομένων \en UCF \gr το οποίο μας βοήθησε 
να εξοικονομήσουμε πολύ χρόνο και πόρους. Αυτό συμβαίνει επειδή κάναμε τα περισσότερα πειράματα μόνο \en JHMDB \gr και αφού βρήκαμε τη
βέλτιστη υλοποίηση, την υλοποιήσαμε για το \en UCF, \gr επίσης.
\section{\tl{JHDMB dataset}}
\subsection{Ταξινομητές \en Linear, SVM  \gr και  \en RNN \gr}


\paragraph{\en Training\gr}
\gr Για να εκπαιδεύσουμε τον ταξινομητή μας, πρέπει να εκτελέσουμε τα προηγούμενα βήματα,
για κάθε βίντεο. Ωστόσο, κάθε βίντεο έχει διαφορετικό αριθμό καρέ και καταλαμβάνει 
μεγάλη ποσότητα μνήμης στη GPU. Για να αντιμετωπίσουμε αυτή την κατάσταση και έχοντας 4 διαθέσιμες \en GPU\gr, δίνουμε
ως είσοδο ένα βίντεο ανά \en GPU\gr. Έτσι μπορούμε να χειριστούμε 4 βίντεο ταυτόχρονα. Αυτό
σημαίνει ότι ένα κλασσικό \en training \gr παίρνει πάρα πολύ χρόνο για μόλις 1 εποχή.
Η λύση με την οποία ήρθαμε, είναι να προυπολογίσουμε τους χάρτες χαρακτηριστικών τόσο για \en action tubes \gr
προσκηνίου όσο και φόντου και στη συνέχεια να τροφοδοτήσουμε
αυτούς τους χάρτες στον ταξινομητή μας για να τον εκπαιδεύσουμε.%  Για συνάρτηση κόστους εκπαιδευσης χρησιμοποιούμε το \en % Cross-Entropy. \gr
Αυτή η λύση περιλαμβάνει τα ακόλουθα βήματα:
\begin{enumerate}
\item Αρχικά, εξαγουμε τους χάρτες χαρακτηριστικών από τα πραγματικά \en action tubes \gr. Ακόμα εξάγουμε τα χαρακτηριστικά από \en
  action tubes \gr φόντου τα οποία είναι διπλάσια στον αριθμό από αυτά του φόντου. Επιλέξαμε αυτή την αναλογία μεταξύ του αριθμού των
  θετικών και αρνητικών \en action tubes \gr εμπνευσμένοι από τους \en\cite{jjfaster2rcnn}\gr, των οποίων η μέθοδος χρησιμοποιεί ποσοστό
  25\% μεταξύ των περιοχών ενδιαφέροντος προσκηνίου και των συνολικών περιοχών, και συνολικά επιλέγει 128 τέτοιες περιοχές. Αντίστοιχα,
  επιλέγουμε ένα λίγο μεγαλύτερο ποσοστό επειδή έχουμε μόνο ένα πραγματικό \en action tube \gr σε κάθε βίντεο. Έτσι, για κάθε βίντεο
  λαμβάνουμε 3 \en action tubes \gr συνολικά, 1 προσκηνίου και 2 φόντου. Θεωρούμε ως \en background action tubes \gr εκείνα που το σκορ
  επικάλυψης τους με οποιοδήποτε \en action tube \gr είναι μεγαλύτερο απο 0.1 αλλά μικρότερο από 0.3 . Φυσικά,προκειμενου να εξάγουμε αυτά
  τα \en action tubes\gr, χρησιμοποιούμε ένα  προεκπαιδευμένο \en TPN, \gr για να μας προτείνει \en ToIs \gr για κάθε τμήμα βίντεο και
  τον προτεινόμενο αλγόριθμο σύνδεσης για να συνδέσουμε αυτά τα \en ToIs\gr. Τελικώς, για κάθε \en action tube \gr λαμβάνουμε
  τους αντίστοιχους χάρτες ενεργοποίησης χρησιμοποιώντας \en 3D RoiAlign. \gr
\item Αφού εξαγουμε αυτά τα χαρακτηριστικά, εκπαιδεύουμε τους ταξινομητές μας. Ο Γραμμικός ταξινομητής χρειάζεται ένα σταθερό μέγεθος
  εισόδου, συνεπώς χρησιμοποιούμε μια συνάρτηση \en pooling \gr στην διάσταση του αριθμού των βίντεο. Έτσι, αρχικά έχουμε ένα
  χάρτη χαρακτηριστικών μεγέθους \textit{3,512,16} και μετά λαμβάνουμε ως έξοδο έναν χάρτη χαρακτηριστικών μεγέθους \textit{512,16}.
  Πειραματιζόμαστε χρησιμοποιώντας αμφότερα \en max \gr και \en avg pooling \gr όπως φαίνεται στον Πίνακα χρησιμοποιώντας  \ref{table:rnn_linear}. Για τον ταξινομητή \en RNN \gr δεν χρειαζόμαστε καμία \en pooling \gr διαδικασία ενώ για τον ταξινομητή \en SVM \gr
  πειραματιζόμαστε ξανά χρησιμοποιώντας   και τις δύο αυτές συναρτήσεις τα αποτελέσματα του οποίου φαίνονται στον Πίνακα \ref{table:svm_first_results}.
\end{enumerate}
\paragraph{\en Validation\gr} Το στάδιο επικύρωσης περιλαμβάνει τη χρήση τόσο προεκπαιδευμένου \en TPN \gr όσο και του ταξινομητή.
Έτσι, για κάθε βίντεο λαμβάνουμε σκορ ταξινόμησης για τα προτεινόμενα \en action tubes\gr.
Οι περισσότερες προσεγγίσεις συνήθως θεωρούν ένα κατώφλι σκορ εμπιστοσύνης πάνω από το οποίο θεωρούν ένα \en action tube \gr
 ως προσκήνιο. Ωστόσο, εμείς δεν χρησιμοποιούμε κανένα σκορ εμπιστοσύνης. Αντιθέτως, επειδή
 γνωρίζουμε ότι \en  JHMDB \gr έχει κομμένα βίντεο με μόνο 1 εκτελούμενη δράση ανά βίντεο, εμείς απλά θεωρούμε το καλύτερο ως προς το
 σκορ \en action tube \gr ως πρόβλεψη.

 \begin{table}[h]
   \en
  \centering
  \begin{tabular}{|| c | c || c  c  c ||}
    \hline
    \multirow{2}{*}{\textbf{Classifier}} & \multirow{2}{*}{\textbf{Pooling}} &  {} & \textbf{mAP} & {} \\
    {} & {} & 0.5 & 0.4 & 0.3 \\
    \hline
    \multirow{2}{*}{Linear} & mean & 14.18 & 19.81 & 20.02 \\
    \cline{2-5}
    {} & max & 13.67 & 16.46 & 17.02 \\
    \hline
    RNN  & -  & 11.3 & 14.14 & 14.84 \\
    \hline
  \end{tabular}
  \caption{First classification results using Linear and RNN classifiers}
  \label{table:rnn_linear}
\end{table}

\begin{center}
  \en
\begin{longtable}{||c | c | c||c c c||}

  \hline
  \multicolumn{2}{||c|}{\textbf{Dimensions}} & \multirow{2}{*}{ \textbf{Pooling}} & \multicolumn{3}{|c||}{\textbf{mAP precision}}\\

   before & after &  {} &  0.5 &  0.4 & 0.3 \\
 \hline   \hline
 \multirow{1}{*}{(k,64,8,7,7)} & \multirow{1}{*}{(1,64,8,7,7)} & \multirow{1}{*}{mean}  &  3.16 & 4.2 & 4.4    \\
 \hline
 \multirow{1}{*}{(k,64,8,7,7)} & \multirow{1}{*}{(1,64,8,7,7)} & \multirow{1}{*}{max}   & 1.11 & 2.35 & 2.71 \\
 \hline   \hline
 \multirow{1}{*}{(k,256,8,7,7)} & \multirow{1}{*}{(1,256,8,7,7)} & \multirow{1}{*}{mean}   &  11.41 & 11.73 & 11.73 \\
 \hline
 \multirow{1}{*}{(k,256,8,7,7)} & \multirow{1}{*}{(1,256,8,7,7)} & \multirow{1}{*}{max}    & \textbf{22.07} & \textbf{24.4} &  \textbf{25.77} \\
  \hline   
  
  \caption{Our architecture's performance using 5 different policies and 2 different feature maps while pooling in
  tubes' dimension. With bold is the best scoring case}
  \label{table:svm_first_results}
\end{longtable} 
\end{center}


\subsection{\en Temporal pooling \gr}

Μετά τη λήψη των πρώτων αποτελεσμάτων, εφαρμόζουμε μια συνάρτηση χρονικής ομαδοποίησης (\en temporal pooling \gr) εμπνευσμένη από το \cite{DBLP:journals/corr/HouCS17}. Χρειαζόμαστε ένα
σταθερό μέγεθος εισόδου για το SVM. Ωστόσο, το χρονικό \en stride \gr των \en action tube \gr μας ποικίλλει από 2 έως 5, αφού ένα βίντεο με 15
καρέ αποτελείεται από 2 συνεχόμενες \en ToIs \gr ενώ ένα βίντεο με 40 καρέ αποτελείται απο 5.
Έτσι χρησιμοποιούμε ως σταθερή χρονική διάσταση ίσον με 2. Ως λειτουργία \en pooling \gr χρησιμοποιούμε \en 3D max poolign\gr,  για κάθε φίλτρο του χάρτη χαρακτηριστικών ξεχωριστά.  Για παράδειγμα, για ένα \en action tube \gr με 4 συνεχόμενες \en ToIs\gr, έχουμε $(4,256, 8, 7, 7)$ ως μέγεθος του χάρτη χαρακτηριστικών. Διαχωρίσουμε το \en feature map \gr  σε 2 ομάδες χρησιμοποιώντας την συνάρτηση \en\textit{linspace} \gr 
και  αναδιαμορφώνουμε το χάρτη χαρακτηριστικών σε $(256, k, 8, 7, 7)$ όπου \tl{k} είναι το μέγεθος της κάθε ομάδας. Αφού κάνουμε
χρήση \en 3D max pooling\gr, θα πάρουμε ένα χαρακτηριστικό χάρτη διαστάσεων $(256, 8, 7, 7)$, ακολούθως τους ενώνουμε και τελικά
λαμβάνουμε χαρακτηριστικών μεγέθους $(2, 256, 8, 7, 7)$. Σε αυτή την περίπτωση δεν πειραματιζόμαστε με χάρτες χαρακτηριστικών μεγέθους
(64, 8, 7, 7)  επειδή με βάση τα παραπάνω αποτελέσματα, δεν θα έχουμε καλύτερη επίδοση απ' τα χαρακτηριστικών μεγέθους $(256, 8, 7, 7)$.
Tα αποτελέσματα  παρουσιάζονται στον πίνακα \ref{table:svm_temp_pooling}, όπου περιλαμβάνεται η καλύτερη προηγούμενη μέθοδος η οποία
χρησιμοποιεί \en max pooling \gr αντί για \en temporal pooling\gr.

\begin{center}
\en
\begin{longtable}{||c | c|  c||c c c||}

  \hline
 \multicolumn{2}{||c|}{\textbf{Dimensions}} & \multirow{2}{*}{\textbf{Temp Pooling}}  &\multicolumn{3}{|c||}{\textbf{mAP precision}}\\

  before & after & {}   & 0.5 &  0.4 & 0.3\\
  \hline   \hline
  \multirow{1}{*}{k,256,8,7,7} & \multirow{1}{*}{1,256,8,7,7} & -  & 22.07 & 24.4 &  25.77 \\
  \hline
  \multirow{1}{*}{k,256,8,7,7} & \multirow{1}{*}{2,256,8,7,7} & Yes & 25.07 & 26.91 & 29.11 \\
  \hline

  \caption{mAP results using temporal pooling for both RoiAlign approaches}
  \label{table:svm_temp_pooling}
\end{longtable} 
\end{center}

\section{Προσθήκη περισσότερων \en groundtruth tubes\gr}

Τα προηγούμενα αποτελέσματα προήλθαν από την εκπαίδευση των ταξινομητών χρησιμοποιώντας μόνο 1
\en action tube \gr προσκηνίου και 2 φόντο. Σκεφτήκαμε ότι θα έπρεπε να πειραματιστούμε 
με τον αριθμό των \en action tubes \gr προσκηνίου καθώς επίσης και  την αναλογία μεταξύ 
των \en action tubes \gr προσκηνίου και φόντου, επειδή στις προηγούμενες προσεγγίσεις
λειτουργήσαμε λιγάκι αυθαίρετα. Έτσι, επιλέγουμε να εκπαιδεύσουμε τους προηγούμενους ταξινομητές  μας χρησιμοποιώντας 2,
4 και 8 \en action tubes \gr προσκηνίου και αναλογία 2:3, 1:2, 1:3 και 1:4 μεταξύ του αριθμού
των \en tubes \gr προσκηνίου και του συνολικού αριθμού τους. \par
Πρώτον, εκπαιδεύουμε το \en RNN \gr ταξινομητή χρησιμοποιώντας χάρτες χαρακτηριστικών με διαστάσεις
$(256, 8, 7, 7)$. Οι επιδόσεις τους με βάση την μετρική \en mAP \gr παρουσιάζονται στον πίνακα \ref{table:rnn_increased}
για το όριο επικάλυψης ίσο με 0,5, 0,4 και 0,3.
\begin{center}
  \en
  \begin{longtable}{|| c | c | c || c c c||}
    \hline
    \multirow{2}{*}{\textbf{F. map}} & \multirow{2}{*}{\textbf{FG tubes}}  & \multirow{2}{*}{\textbf{Total tubes}} & {} & \textbf{mAP} & {} \\
    {}  & {} & {} & 0.5 & 0.4 & 0.3 \\
    \hline
    \multirow{7}{*}{(k,256,8,7,7)} & 1 & 3 & 11.3 & 14.14 & 14.84 \\
    \cline{2-6}
    {} & \multirow{4}{*}{2} & 3 & 1.96 & 5.07 & 7.27 \\
    \cline{3-6}
    {} & {} & 4  & 3 & 5.03 & 5.77 \\
    \cline{3-6}
    {} & {} & 6 & 1.34 & 3.89 & 4.49 \\
    \cline{3-6}
    {} & {} & 8 & 0.77 & 1.51 & 2.72 \\
    \cline{2-6}
    {} & \multirow{4}{*}{4} &  6 & 13.23 & 21.74 & 25.4 \\
    \cline{3-6}
    {} & {} & 8 & 20.73 & 28.25 & 29.50 \\
    \cline{3-6}
    {} & {} & 12  & 16.55 & 24.35 & 25.22 \\
    \cline{3-6}
    {} & {} & 16  & 20.11 & 25.50 & 27.62 \\
    \cline{2-6}
    {} & \multirow{4}{*}{8} & 12 & 13.82 & 19.93 & 22.80 \\
    \cline{3-6}
    {} &  {} & 16 & 15.47 & 23.08 & 24.19 \\
    \cline{3-6}
    {} &  {} & 24 & 15.88 & 23.44 & 24.48  \\
    \cline{3-6}
    {} &  {} & 32 &  12.66 & 23.50 & 25.61 \\
    \hline

  \caption{RNN results }
  \label{table:rnn_increased}
\end{longtable}
\end{center}

Σύμφωνα με τον πίνακα  \ref{table:rnn_increased}, πρώτον, μπορούμε να δούμε ότι η αύξηση του αριθμού των
\en action tubes \gr προσκηνίου από 1 έως 2 οδηγούν στη απότομη μείωση της  απόδοσης του \en mAP\gr.
Αλλά, όταν θέτουμε τα \en action tubes \gr προσκηνίου ίσα με 4 έχουμε καλύτερα αποτελέσματα. Πάνω σ' αυτό,
έχουμε την καλύτερη απόδοση όταν η αναλογία είναι ίση με 1:2 και 1:4. Τέλος, όταν
 ορίζουμε τον αριθμό των \en tubes \gr προσκηνίου ίσο με 8, η απόδοση βελτιώνεται ελαφρώς
σε σύγκριση με τις αρχικές επιλογές (1 \en action tube \gr προσκηνίου και 3 συνολικά) , αλλά η κατάσταση αυτή δεν
να μας φέρεις τα καλύτερα αποτελέσματα. \par
Στη συνέχεια, είναι καιρός να πειραματιστούμρ χρησιμοποιώντας τη γραμμική ταξινόμηση. Χρησιμοποιούμε ξανά το
ίδιες υποθέσεις όπως κάναμε και για την ταξινόμηση με \en RNN\gr. Όπως προαναφέρθηκε, χρειαζόμαστε μια
μέθοδο ομαδοποίησης (\en pooling\gr) πριν από το βήμα ταξινόμησης. Σύμφωνα με τον πίνακα \ref{table:rnn_linear}, η μέθοδος
του \en avg pooling \gr έχει ως αποτέλεσμα καλύτερη απόδοση \en mAP \gr από τo \en max pooling \gr, οπότε χρησιμοποιούμε \en avg pooling \gr
 για όλες τις ακόλουθες περιπτώσεις. Τα αποτελέσματα περιλαμβάνονται στον πίνακα \ref{table:linear_increased}.
 \begin{center}
   \en
  \begin{longtable}{|| c | c | c || c c c||}
    \hline
    \multirow{2}{*}{\textbf{F. map}} & \multirow{2}{*}{\textbf{FG tubes}} & \multirow{2}{*}{\textbf{Total tubes}} & {} & \textbf{mAP} & {} \\
    {}  & {} & {} & 0.5 & 0.4 & 0.3 \\
    \hline
    \multirow{7}{*}{(k,256,8,7,7)}  & 1 & 3& 14.18 &19.81 & 20.02 \\
    \cline{2-6}
    {} & \multirow{4}{*}{2} & 3 & 12.68 & 13.38 & 15.14 \\
    \cline{3-6}
    {} & {} & 4 & 11.5 & 14.95 & 16.22 \\
    \cline{3-6}
    {} & {} & 6 & 10.74 & 13.36 & 15.18 \\
    \cline{3-6}
    {} & {} & 8 & 8.00 & 9.83 & 11.17 \\
    \cline{2-6}
    {} & \multirow{4}{*}{4} & 6 & 15 & 17.55 & 19.39 \\
    \cline{3-6}
    {} & {} & 8 & 17.04	& 20.12 &22.07 \\
    \cline{3-6}
    {} & {} & 12 & 17.57 & 19.9 & 21.88 \\
    \cline{3-6}
    {} & {} & 16 & 14.24 & 17.24 & 17.95 \\

    \cline{2-6}
    {} & \multirow{4}{*}{8} & 12 & 17.91 & 22.51 & 24.62 \\
    \cline{3-6}
    {} & {} & 16 & 16.76 & 20.34 & 22.72 \\
    \cline{3-6}
    {} & {} & 24 & 17.61 & 19.12 & 24.48 \\
    \cline{3-6}
    {} & {} & 32 & 14.45 & 18.07 & 19.14  \\
    \hline

    \caption{Linear results }
    \label{table:linear_increased}
  \end{longtable}
\end{center}

Πρώτα απ ' όλα, μετά την εξέταση των αποτελεσμάτων που παρουσιάστηκαν στους δύο πίνακες \ref{table:rnn_increased} και \ref{table:linear_increased},
είναι σαφές ότι όταν ορίζουμε τον αριθμό των \en action tubes \gr προσκηνίου ίσο με 2, και για
τις δύο περιπτώσεις, έχουμε χειρότερα αποτελέσματα απ' το αρχικό. Αυτό μάλλον οφείλεται στο γεγονός
ότι αυξάνουμε επίσης τον αριθμό των \en action tubes \gr φόντου για περιπτώσεις όταν η αναλογία είναι 1:2,
1:3 και 1:4 με αποτέλεσμα να θεωρούν οι ταξινομητές τα περισσότερα προτεινόμενα \en action tubes \gr ότι είναι φόντου.
Από την άλλη πλευρά, όταν έχουμε ορίσει αναλογία ίση με 2:3, αντί να θεωρήσουν τα περισσότερα προτεινόμενα \en action tubes, \gr
ως φόντο, τα ταξινομούν ως μια συγκεκριμένη δράση τάξη, που σημαίνει ότι καταλήγομε σε κατάσταση \en overfitting\gr.
Έτσι, αν και πιστεύουμε ότι δεν θα πρέπει να ερευνήσουμε για περιπτώσεις με 2 \en action tubes \gr που ανήκουν στο προσκήνιο,
θα εκπαιδεύσουμε τoν \en SVM  \gr ταξινομητή μας  χρησιμοποιώντας 2 \en action tubes \gr προσκηνίου και όλα τα προαναφερθέντα
ποσοστά επειδή θέλουμε να είμαστε βέβαιοι για την υπόθεσή μας. Από την άλλη πλευρά,
παρατηρούμε ότι η χρήση 4 ή 8 \en action tubes \gr μας οδηγεί σε καλύτερα αποτελέσματα από το
τα αρχικά αποτελέσματα. Οι καλύτερες επιδόσεις έρχονται όταν η αναλογία μεταξύ των αριθμών των \en action tubes \gr  προσκηνίου και συνολικών
 είναι 1:3 και για τις δύο περιπτώσεις. Παράλληλα, έχουμε καλά αποτελέσματα για τις αναλογίες 2:3 και 1:2, και
λαμβάνουμε την χειρότερη επίδοση όταν  χρησιμοποιούμε αναλογία 1:4. Αυτό προκαλείται μάλλον από το μεγάλο
αριθμός \en action tubes \gr φόντου σε σχέση με τον αριθμό των \en action tubes \gr προσκηνίου.
Όπως προαναφέρθηκε, εκπαιδεύουμε τον  ταξινομητή \en  SVM \gr χρησιμοποιώντας τις προαναφερθείσες περιπτώσεις
Οι επιδόσεις ταξινόμησης με χρήση της μέτρησης mAP εμφανίζονται στον πίνακα \ref{table:svm_increased}. .

\begin{center}
  \en
  \setlength{\tabcolsep}{2pt}
  \begin{longtable}{|| c | c | c || c c c||}


    \hline
    \multirow{2}{*}{\textbf{F. map}} & \multirow{2}{*}{\textbf{FG tubes}} & \multirow{2}{*}{\textbf{Total tubes}} & {} & \textbf{mAP} & {} \\
    {}  & {} & {} & 0.5 & 0.4 & 0.3 \\
    \hline
    \multirow{8}{*}{(2,256,8,7,7)} & 1 & 3 & 24.97 & 26.91 & 29.11\\
    \cline{2-6}
    {} & \multirow{4}{*}{2} & 3 & 13.87 & 18.74 & 21.29 \\
    \cline{3-6}
    {} & {} & 4 & 14.21 & 19.67 & 21.75 \\
    \cline{3-6}
    {} & {} & 6 & 12.88 & 18.62 & 21.59 \\
    \cline{3-6}
    {} & {} & 8 & 12.66 & 18.7 & 21.97 \\
    \cline{2-6}
    {} & \multirow{4}{*}{4} & 6 & 25.04 & 26.91 & 27.82  \\
    \cline{3-6}
    {} & {} &  8 & 24.34 & 25.67 & 26.34 \\
    \cline{3-6}
    {} & {} & 12 &  23.47 & 25.31 & 25.9 \\
    \cline{3-6}
    {} & {} & 16 & 21.94 & 23.55 & 24.23 \\
    \cline{2-6}
    {} & \multirow{4}{*}{8} & 12 & 24.83 & 27.13 & 27.46 \\
    \cline{3-6}
    {} & {} & 16 & 23.97 & 26.38 & 26.94 \\
    \cline{3-6}
    {} & {} & 24 & 24.17 & 26.24 & 26.76 \\
    \cline{3-6}
    {} & {} & 32 & 24.17 & 26.24 & 26.76 \\

    \hline

    \caption{SVM results }
    \label{table:svm_increased}
  \end{longtable}
\end{center}

Τα αποτελέσματα μας δείχνουν κάποια ενδιαφέροντα γεγονότα. Πρώτον, επιβεβαιώνουν την υπόθεσή μας
ότι το δίκτο είναι αδύνατον να εκπαιδευτεί με μόνο 2 \en action tubes \gr προσκηνίου.
Επίσης, παρατηρούμε ότι έχουμε σχεδόν τα ίδια αποτελέσματα με
τα αποτελέσματα που προέκυψαν για τη χρήση της πολιτικής 1, μόνο ένα \en action tube \gr προσκηνίου, 3 συνολικά και
χρονικό \en pooling, \gr γεγονός το οποίο είναι λίγο παράξενο. Αυτό είναι μάλλον επειδή κατά τη διάρκεια του υπολογισμού της κλίμακας,
στο στάδιο εκπαίδευσης, δεν έχουμε τόσο
καλό δείγμα βίντεο όπως κάναμε κατά τη διάρκεια της προαναφερθείσας περίπτωσης. Αλλά θεωρούμε ότι είναι καλύτερο να συνεχίσoυμε
τις δοκιμές χρησιμοποιώντας 4 ή 8 \en action tubes \gr προσκηνίου. Τελευταίό
αλλά όχι λιγότερο σημαντικό, είναι σαφές ότι έχουμε το καλύτερο αποτέλεσμα όταν έχουμε μια ποσοστό 2:3
μεταξύ του αριθμού των \en action tubes \gr προσκηνίου και των συνολικών. Επίσης, είναι πιο προτιμότερο
να έχουμε 4 \en action tube \gr προσκηνίου αντί για 8. Αυτό σημαίνει ότι επειδή έχουν δοθεί πάρα πολλά
το \en SVM  \gr μπερδεύεται, και έτσι αποτυγχάνει να λειτουργήσει αποτελεσματικά.

\section{Ταξινομητής \en MultiLayer Perceptron (MLP)}
\begin{figure}[h]
  \en
  % \includegraphics[scale=0.7]{convolutional_neural_network_structure} \]
  \centering
  \includegraphics[scale=0.42]{mlp}
  \caption{Structure of the MLP classifier}
  \label{fig:mlp_structure}
\end{figure}
\gr
Σε προηγούμενες ενότητες χρησιμοποιήσαμε κλασσικούς ταξινομητές όπως τον Γραμμικό, ένα \en RNN \gr και \en SVM\gr.
Τελευταίoi αλλά εξίσου σημαντικoi, μια άλλη ευρέως κατηγορία ταξινομητών είναι οι \en Multilayer Perceptron (MLP)\gr.
Σχεδιάζουμε ένα MLP όπως φαίνεται στο σχήμα \ref{fig:mlp_structure} για διάρκεια δείγματος ίση με 8, και περιγράφεται κατωτέρω:

\begin{itemize}
\item Στην αρχή, μετά το \en 3D Roi Align \gr και για  διάρκεια του δείγματος ίση με  8 καρέ,
λαμβαουμε ένα χάρτη ενεργοποίησης μεγέθους  $(k, 256, 8, 7, 7)$ όπου k είναι ο αριθμός των συνδεδεμένων ToIs. Εμπνευσμένοι
από προηγούμενες ενότητες, εκτελούμε \en temporal pooling \gr ακολουθούμενο  από
\en max pooling \gr  στην  διάσταση της διάρκειας του δείγpματος. Έτσι, έχουμε τώρα έναν χάρτη χαρακτηριστικών 
με διαστάσεις ίσες με (2, 256, 7, 7), τις οποίες αναδιαμορφώνουμε σε
(256, 2, 7, 7) και τροφοδοτούμε \en layers \gr που εξήχθησαν από το τελευταίο στάδιο του \en ResNet34\gr.
Αυτά τα στάδια περιλαμβάνουν 3 \en Residual Layers \gr  με stride  ίσο με 2 σε όλες τις 3
διαστάσεις και αριθμός εξόδου φίλτρων ίσου με 512.
\item Μετά τα \en Residual Layers\gr, κάνουμε \en avg pooling \gr για τις διαστάσεις x-y.
Έτσι, έχουμε ως χάρτες ενεργοποίησης εξόδου με μέγεθος διαστάσεων ίσο με (512,).
Τέλος, τροφοδοτούμε  αυτoύς  τους  χαρακτηριστικούς  χάρτες σε ένα γραμμικό \en layer \gr προκειμένου να εξάγουμε την κλάση
του υποψήφιου \en action tube, \gr μετά την εφαρμογή της λειτουργίας Soft-Max.
\end{itemize}

\subsection{Κλασσικό \en training}
Όπως προαναφέρθηκε προηγουμένως, ο κώδικας εκπαίδευσης απαιτεί την εκτέλεση ενός μόνο βίντεο ανά GPU, επειδή τα βίντεο έχουν διαφορετική διάρκεια.
Για προηγούμενες προσεγγίσεις, μας ήρθδε η  ιδέα του προυπολογισμού των χαρακτηριστικά των \en action tubes \gr του βίντεο και στη συνέχεια
εκπαιδεύουμε μόνο τον ταξινομητή. Ωστόσο, για αυτό το βήμα, εκπαιδεύσαμε τον ταξινομητή μας με τον κλασιικό τρόπο για να λάβουμε
αποτελέσματα ταξινόμησης. Φυσικά, χρησιμοποιήσαμε ένα προεκπαιδευμένο \en TPN\gr, του οποίο παγώσαμε τα \en layers \gr για να μην εκπαιδευτούν.
Προσπαθήσαμε να εξερευνήσουμε διαφορετικές αναλογίες μεταξύ του αριθμού των \en action tubes \gr προσκηνίου και του συνολικού αριθμού των
\en action tubes \gr ανά βίντεο. Οι πρώτες 3 προσομοιώσεις περιλαμβάνουν σταθερό αριθμό συνολικών \en action tubes \gr και μεταβλητή αναλογία
μεταξύ του αριθμού των \en action tubes \gr προσκηνίου και φόντου. Αρχίσαμε χρησιμποιώντας μόνο \en action tubes \gr προσκηνίου, το  οποίο
σημαίνει ότι 32 από 32 \en action tube  \gr είναι προσκηνίου, μετά τα μισά από τα προτεινόμενα  \en action tubes, \gr δηλαδή 16 από 32 και
τέλος λιγότερο από το ήμισυ, δηλαδή 14 από τις 32.
Μετά από αυτό, πειραματιζόμαστε χρησιμοποιώντας έναν σταθερό αριθμό \en action tubes \gr προσκηνίου και μεταβλητού αριθμού συνολικών, o oποίος είναι 16, 24 και 32. Τα αποτελέσματα των επιδόσεων παρουσιάζονται στον πίνακα \ref{table:mlp_reg}.

\begin{center}
  \en
  \begin{longtable}{|| c | c || c c c ||}
    \hline
    \multirow{2}{*}{\textbf{FG tubes}} & \multirow{2}{*}{\textbf{Total tubes}} & {} &  \textbf{mAP} & {} \\
    {} & {} & 0.5 & 0.4 & 0.3 \\
    \hline
    32 & \multirow{3}{*}{32} &1.28 & 1.73 & 1.87  \\
    \cline{1-1} \cline{3-5}
    16 & {} & 3.98 & 4.38 & 4.38  \\
    \cline{1-1} \cline{3-5}
    14 & {} & 0.40 & 0.40 & 0.40 \\
    \hline
    \multirow{3}{*}{8} & 16 & 9.41 & 12.59 & 14.61 \\
    \cline{2-5}
    {} & 24 & 12.32 & 15.53 & 18.57 \\
    \cline{2-5}
    {} & 32 & 7.16 & 10.92 & 13.00 \\
    \hline
    \caption{MLP's mAP performance for regular training procedure}
    \label{table:mlp_reg}
  \end{longtable}
\end{center}

Τα αποτελέσματα δείχνουν ότι όταν οι πρώτες 3 προσεγγίσεις μας δίνουν πολύ άσχημα αποτελέσματα.
Συγκρίνοντας τους με τους υπόλοιπους 3, ήρθαμε με το συμπέρασμα ότι χρειαζόμαστε
το πολύ 8 \en action tubes \gr προσκηνίου, ακόμη και όταν ο λόγος μεταξύ του αριθμού \en action tubes \gr
του προσκηνίου και του φόντου είναι υπέρ του δεύτερου. Πιθανότατα, πάρα πολλοί
\en action tubes \gr προσκηνίου κάνουν την αρχιτεκτονική μας να έρθει σε κατάσταση \en overfitting \gr και
συνεπώς να είναι ανίκανη να γενικεύει.

\subsection{Εξαγωγή χαρακτηριστικών}

Όπως εκτελέστηκε προηγουμένως, εκπαιδεύσαμε τον ταξινομητή \en MLP \gr χρησιμοποιώντας προ-υπολογισμένους
χάρτες χαρακτηριστικών. Αυτοί οι χάρτες περιλαμβάνουν τόσο \en action tubes \gr που είναι στο  προσκήνιο όσο φόντου. Με
βάση τα συμπεράσματα που προέκυψαν  στα προηγούμενα τμήματα, θα εκπαιδεύσουμε
μόνο για  αριθμό \en action tube \gr προσκηνίου ίσο με 4 και 8. Επιπλέον
Θα  εκπαιδεύσουμε τον ταξινομητή μας για 3 διαφορετικές αναλογίες, οι οποίες είναι 1:1, 1:2 και 1:3.
Ο πίνακας \ref{table:mlp_extract_jhdmb} δείχνει αυτές τις περιπτώσεςι καθώς 
και τις αντίστοιχες επιδόσεις του \en mAP \gr κατά τη διάρκεια του βήματος επικύρωσης.
\begin{center}
  \en
  \begin{longtable}{|| c | c || c c c ||}
    \hline
    \multirow{2}{*}{\textbf{FG tubes}} & \multirow{2}{*}{\textbf{Total tubes}} & {} & \textbf{mAP} & {} \\
    {} & {} & 0.5 & 0.4 & 0.3 \\
    \hline
    \multirow{3}{*}{4} & 6 & 4,37 & 8,54 & 10,12 \\
    \cline{2-5}
    {} & 8 & 5.89 & 9.54 & 13.61 \\
    \cline{2-5}
    {} & 12 & 9.51 & 12.8 & 14.6  \\
    \cline{2-5}
    {} & 16 & 6.80 & 13.17 & 14.67 \\
    \hline
    \multirow{4}{*}{8} & 12 & 8,62 & 12,32 & 14,74 \\
    \cline{2-5}
    {} & 16 & 8.49 & 13.94 & 15.09 \\
    \cline{2-5}
    {} & 24 & 6.72 & 12.17 & 15.30 \\
    \cline{2-5}
    {} & 32 & 13.27 & 17.64 & 18.97 \\
    \hline

  \caption{mAP results for MLP trained using extracted features}
  \label{table:mlp_extract_jhdmb}
\end{longtable}
\end{center}

Συγκρίνοντας τα αποτελέσματα από τους πίνακες \ref{table:mlp_extract_jhdmb}  και \ref{table:mlp_reg}, είναι σαφές ότι χρειαζόμαστε 8
\en tubes \gr προσκηνίου για να λειτουργεί καλά ο ταξινομητής \en MLP. \gr  Ωστόσο, δεν είναι πολύ σαφές ποια από
τις  δύο προτεινόμενες εκπαιδευτικές διαδικασίες είναι καλύτερη, αλλά αν πρέπει να αποφασίσουμε μία
μέθοδο, θα επιλέξουμε τη χρήση προϋπολογισμένων χαρακτηριστικών. Η προσέγγιση αυτή
κατορθώνει να επιτύχει τα καλύτερα αποτελέσματα, και ειδικά όταν έχουμε 8
\en tubes \gr προσκηνίου και 32 συνολικά. Επίσης, συγκρίνοντας τις μεθόδους με 4 ή 8 θετικά
\en action tubes\gr, είναι σαφές ότι θα προτιμούσαμε να χρησιμοποιούμε 8 γενικά. Ωστόσο, δεν είναι
σαφές ποια αναλογία είναι καλύτερη, επειδή, έχουμε καλύτερα αποτελέσματα όταν έχουμε 8
\en action tubes \gr και αναλογία 1:4 ενώ έχουμε καλύτερα αποτελέσματα όταν η αναλογία είναι 1:3
με 4 \en action tubes.\gr

\section{\en UCF dataset\gr}
\subsection{Εισαγωγή}
Κατά τη διάρκεια της προηγούμενης ενότητας, διερευνούμε διαφορετικές μεθόδους ταξινόμησης χρησιμοποιώντας
διάφορες τάξεις.  Λαμβάνοντας υπόψη την απόδοση των \en recall \gr και \en MABO \gr που παρουσιάζονται στο κεφάλαιο 4,
είναι σαφές ότι το δίκτυό μας θα αποτύχει να αναγνωρίσει τα περισσότερα πραγματικά
 χωροχρονικά \en action tubes \gr και να τα ταξινομήσει σωστά. Ωστόσο
στις περισσότερες περιπτώσεις, η απόδοση του MABO πήρε Βαθμολογία περίπου 92-94\%. Οπότε, μας ήρθε η ιδέα
 να μην εκτελέσουμε  χωροχρονικό εντοπισμό και ταξινόμηση,
για το σύνολο δεδομένων \en UCF\gr, αλλά μόνο χρονικό εντοπισμό. Αυτό σημαίνει ότι
προσπαθούμε να ανιχνεύσουμε  τα τμήματα βίντεο στα οποία εκτελείται μια ενέργεια, και επίσης προσπαθούμε
 να προσδιορίσουμε την κλάση της εκτελεσμένης ενέργειας.
\subsection{Χρονικός εντοπισμός}

Όπως παρουσιάζεται στο κεφάλαιο 4, ο αλγόριθμος σύνδεσής μας είναι σε θέση να πάρει καλή απόδοση χρονικού 
\en recall \gr και  \en MABO\gr. Για τον χρονικό εντοπισμό μιας  δράσης σε
βίντεο, χρησιμοποιούμε μόνο τις χρονικές πληροφορίες που περιέχουν  τα προτεινόμενα \en action tubes\gr,
που ισοδυναμούν με το πρώτο και το τελευταίο καρέ του \en tube\gr. Θα ταξινομήσουμε τα προτεινόμενα \en action tubes \gr
χωρίς να πραγματοποιήσουμε χωροχρονικό εντοπισμό, αλλά μόνο χρονικό. Αν και δεν χρησιμοποιούμε τα προτεινόμενα πλαίσια ανά καρέ
για την ταξινόμηση, εκμεταλλευόμταστε τις χωρικές πληροφορίες τους για να
να εκτελέσουμε  καλύτερo χρονικό εντοπισμό. Διαισθητικά, αυτό συμβαίνει επειδή, για να
να εξαγάγουμε τα \en action tubes\gr, λαμβάνουμε υπόψιν μας τη χωρική επικάλυψη μεταξύ των συνδεδεμένων \en ToIs\gr.

Η προαναφερθείσα προσέγγιση περιλαμβάνει τα ακόλουθα βήματα:
\begin{enumerate}
\item Αρχικά, χρησιμοποιούμε το \en TPN  \gr για να προτείνουμε χωροχρονικά ToIs, όπως ακριβώς κάναμε
στις προηγούμενες προσεγγίσεις. Στη συνέχεια, συνδέουμε αυτά τα ToIs με βάση τον προτεινόμεν αλγόριθμο
του κεφαλαίου 4, με τη χρήση του χωροχρονικoύ αλγορίθμου \en NMS \gr με κατώφλι σύνδεσης
 ίσο με 0,9, για την αφαίρεση επικαλυπτόμενων \en action tubes\gr.
\item Tα επόμενα βήματα είναι ακριβώς τα ίδια με τις προηγούμενες προσεγγίσεις ταξινόμησης.
Ωστόσο, σε αυτή την προσέγγιση, δεν χρησιμοποιούμε κανένα είδος \en ROI Aling \gr για να
εξάγουμε τους χάρτες χαρακτηριστικών των \en action tubes\gr. Αντιθέτως, για όλες τις προτεινόμενες
ακολουθίες από πλαίσια, βρίσκουμε τη διάρκειά τους, δηλαδή  το πρώτο και τελευταίο τους καρέ.
Μετά από αυτό, τρέχουμε τον αλγόριθμο του χρονικόυ \en NMS \gr  για να αφαιρέσουμε  αλληλοεπικαλυπτόμενα \en action tubes\gr.
 Η μόνη διαφορά μεταξύ του χωροχρονικού και χρονικόυ \en NMS \gr είναι ο
το κριτήριο επικάλυψης, το οποίο χρησιμοποιείται. Για τα χωροχρονικό \en NMS \gr χρησιμοποιούμε το τρισδιάστατο \en IoU, \gr ενώ 
 αντίστοιχα, για το χρονικό \en NMS, \gr το μονοδιάστατο.

\item Φυσικά, τα προτεινόμενα \en action tubes \gr διαρκούν περισσότερο από 16 καρέ
  που ορίζεται ως διάρκεια δείγματος. Έτσι, διαχωρίζουμε τα προτεινόμενα \en action tubes \gr σε βίντεο κλιπ
  διάρκειας 16 καρέ (όπως η διάρκεια του δείγματός μας). Αυτά τα τμήματα βίντεο δίνονται ως είσοδο
και πάλι σε ένα  3D resNet34 (\cite{hara3dcnns}), το οποίο, αυτή τη φορά, δεν το χρησιμοποιούμε μόνο για
 εξαγωγής χαρακτηριστικών, αλλά και για ταξινόμηση  κάθε τμήματος βίντεο.
\item Έτσι, για κάθε βίντεο κλιπ, για κάθε κλάση έχουμε ένα σκορ εμπιστοσύνης μετά την
λειτουργία του softmax. Τέλος, υπολογίζουμε τη μέση βαθμολογία εμπιστοσύνης για
σε κάθε κλάση, και θεωρούμε την κλάση με τη βέλτιστη βαθμολόγηση ως ετικέτα του 
\en action tube\gr. Φυσικά, μερικα \en action tubes \gr μπορεί να μην περιέχουν καμία ενέργεια,
Έτσι έχουμε ορίσει ένα κατώφλι  εμπιστοσύνης για ξεχωρίσουμε τα \en action tubes  \gr  προσκηνίου με αυτά του
φόντο.
\end{enumerate}
\paragraph{\tl{Training}} Το μόνο εκπαιδεύον μέρος αυτής της αρχιτεκτονικής είναι το ResNet34. Χρησιμοποιούμε
ένα προεκπαιδευμένο TPN, όπως παρουσιάζεται στο κεφάλαιο 4. Η διαδικασία κατάρτισης ResNet34
με βάση τον κωδικό που δόθηκε από το [?]. Το τροποποιήσαμε για να μπορούμε να εκπαιδευόμαστε
για το σύνολο δεδομένων UCF-101, μόνο για τις 24 τάξεις, για τις οποίες υπάρχουν
και η TPN μας είναι εκπαιδευμένη.
\paragraph{\tl{Validation}} Με βάση τα προαναφερθέντα βήματα, είναι σαφές ότι οι παράμετροι
που μπορούν να τροποποιηθούν είναι τα χρονικά όρια και το όριο
να αποφασίζουν εάν μια ενέργεια περιέχεται ή όχι. Όλοι οι διαφορετικοί συνδυασμοί που χρησιμοποιούνται
κατά τη διάρκεια της επικύρωσης παρουσιάζονται στον πίνακα 1,20.

\begin{center}
  % \setlength{\tabcolsep}{2pt}
  \begin{longtable}{|| c | c || c c c ||}

    \hline
    \multirow{2}{*}{\textbf{NMS thresh}} & \multirow{2}{*}{\textbf{Conf thresh}} & {} & \textbf{mAP} & {}  \\
    {} & {} & 0.5 & 0.4 & 0.3\\
    \hline
    \multirow{3}{*}{0.9} & {0.6} & 0.3 & 0.54 & 0.64 \\
    \cline{2-5}
    {} & {0.75} & 0.25 & 0.45 & 0.55 \\
    \cline{2-5}
    {} & {0.85} & 0.2 & 0.38 & 0.49  \\
    \hline
    \multirow{3}{*}{0.7} & {0.6} & 0.63 & 1.02 & 1.27 \\
    \cline{2-5}
    {} & {0.75} & 0.5 & 0.84 & 1.05 \\
    \cline{2-5}
    {} & {0.85} & 0.4 & 0.68 & 0.89 \\
    \hline
    \multirow{3}{*}{0.5} & {0.6} & 0.96 & 1.21 & 1.75 \\
    \cline{2-5}
    {} & {0.75} &  0.63 & 0.93 & 1.38 \\
    \cline{2-5}
    {} & {0.85} & 0.57 & 0.72 & 1.03 \\
    \hline
    \multirow{3}{*}{0.4} & {0.6} & 1.07 & 1.52 & 2.03 \\
    \cline{2-5}
    {} & {0.75} &  0.79 & 1.18 & 1.63 \\
    \cline{2-5}
    {} & {0.85} & 0.71 & 0.98 & 1.33 \\
    \hline
    \multirow{3}{*}{0.3} & {0.6} & 1.1 & 1.66 & 2.53 \\
    \cline{2-5}
    {} & {0.75} &  0.93 & 1.39 & 2.08 \\
    \cline{2-5}
    {} & {0.85} & 0.81 & 1.12 & 1.6 \\
    \hline
    \multirow{3}{*}{0.2} & {0.6} & 0.84 & 1.38 & 2.17 \\
    \cline{2-5}
    {} & {0.75} & 0.73 & 1.13 & 1.78 \\
    \cline{2-5}
    {} & {0.85} & 0.65 & 0.81 & 1.31 \\

    \hline

    \caption{UCF's temporal localization mAP performance}
    \label{table:temp_cls_1}
  \end{longtable}
\end{center}

\begin{center}
  % \setlength{\tabcolsep}{2pt}
  \begin{longtable}{|| c || c c c | c |}
    \hline
    \multirow{2}{*}{\textbf{NMS thresh}} & {} & {\textbf{Recall}} & {} & \multirow{2}{*}{\textbf{MABO}} \\
      {} & 0.9 & 0.8 & 0.7 & {} \\
      \hline
      0.9 & 0.7361 & 0.8935 & 0.9422 & 0.9138130172 \\
      \hline
      0.7 & 0.3194 & 0.6875 & 0.9293 & 0.8412186326 \\
      \hline
      0.5 & 0.1757 & 0.3331 & 0.6281 & 0.7471525429 \\
      \hline
      0.4 &0.1483 & 0.2829 & 0.4707 & 0.6986400756 \\
      \hline
      0.3 & 0.111 & 0.2038 & 0.3848 & 0.6429232202 \\
      \hline
    \caption{UCF's temporal localization recall and MABO performances}
    \label{table:temp_cls_recall_1}
  \end{longtable}
\end{center}

Σύμφωνα με τον πίνακα 1,20, οι επιδόσεις του mAP για τη χρονική
η ταξινόμηση είναι πολύ κακή. Η καλύτερη απόδοση είναι περίπου 2%,
πολύ χαμηλά. Συγκρίνοντας αυτά τα αποτελέσματα με τα αποτελέσματα που εμφανίζονται στον πίνακα 1,21, συμπεραίνουμε
ότι η μέθοδός μας δεν είναι καθόλου αποδοτική. Παρόλο που τα αποτελέσματα του mAP αυξάνονται
και η απόδοση του MABO μειώνεται ταχέως. Φυσικά, αυτό το αποτέλεσμα
Δεδομένου ότι, μειώνοντας το όριο του νμμs, ο αριθμός των απορριπτθέντων
σωλήνες δράσης αυξάνεται.
Δοκιμάσαμε μια άλλη προσέγγιση, η οποία εφαρμόζει τον αλγόριθμο
και όχι πριν από αυτό όπως κάναμε προηγουμένως. Επίσης, παρατηρήσαμε σε προηγούμενες
στις περισσότερες περιπτώσεις, έχουμε αυτές τις χαμηλές επιδόσεις λόγω της
με ψευδή θετικά αποτελέσματα, τα οποία δεν αφαιρούνται κατά τη διάρκεια της διαδικασίας. Να είμαι
πιο συγκεκριμένα, ο πίνακας 1,22 δείχνει όλα τα πραγματικά και ψευδώς θετικά
ορίζεται το όριο του ννs ίσο με 0,2, όριο επικάλυψης mAP ίσο με 0,3
και όριο εμπιστοσύνης ίσο με 0,6 για τις δύο προαναφερθείσες προσεγγίσεις.

\begin{center}
  \setlength{\tabcolsep}{2pt}
  \begin{longtable} {|| c | c c | c c | c | cc | cc||}

    \hline
    \multirow{2}{*}{\textbf{Class}} & \multicolumn{2}{|c|}{\textbf{Appr 1}}  & \multicolumn{2}{ c||}{\textbf{Appr 2}} &
    \multirow{2}{*}{\textbf{Class}} & \multicolumn{2}{|c|}{\textbf{Appr 1}}  & \multicolumn{2}{ c||}{\textbf{Appr 2}} \\
    {} & TP & FP & TP & FP &
    {} & TP & FP & TP & FP \\
    \hline    
    Basketball & 5 & 279 & 6 & 403 &
    BasketballDunk & 7 & 7 & 12 & 13 \\
    Biking & 0 & 3 & 0 & 5 &
    CliffDiving & 11 & 55 & 1 & 1 \\
    CricketBowling &  0 & 0 & 10 & 75 &
    Diving & 20 & 189 & 23 & 272 \\
    Fencing & 11 & 222 & 25 & 336 &
    FloorGymnastics & 2 & 86 & 6 & 131 \\
    GolfSwing & 4 & 51 & 6 & 78&
    HorseRiding & 0 & 33 & 4 & 58 \\
    IceDancing & 8 & 29 & 6 & 38 &
    LongJump & 1 & 24 & 6 & 43 \\
    PoleVault & 0 & 202 & 9 & 296 &
    RopeClimbing & 1 &24 & 4 & 43 \\
    SalsaSpin & 3 & 158 & 5 & 237 &
    SkateBoarding & 0 & 10 & 0 & 13 \\
    Skiing & 0 & 0 & 0 & 0 &
    Skijet & 1 & 27 & 6 & 43 \\
    SoccerJuggling & 3 & 94 & 1 & 153 &
    Surfing  & 11 & 102 & 23 & 159 \\
    TennisSwing & 0 & 125 & 0 & 166 &
    TrampolineJumping & 4 & 18 & 4 & 32 \\
    VolleyballSpiking & 20 &704 & 20 & 1044 &
    WalkingWithDog & 0 & 5 & 0 & 9 \\
    \hline    
    \caption{Comparing TP and FP for both approaches}
    \label{table:tp_fp}

  \end{longtable}
\end{center}

Λαμβάνοντας υπόψη αυτά τα δύο γεγονότα, ήρθαμε με την ακόλουθη λύση. Στην
προσέγγιση, ταξινομήσαμε τους υποψήφιους σωλήνες δράσης χρησιμοποιώντας βαθμολογίες σύνδεσης που
από τη σύνδεση του αλγορίθμου και μετά αφαιρέσαμε τους σωλήνες δράσης. In
η νέα προσέγγισή μας, αφαιρούμε πρώτα τους σωλήνες δράσης με τα ίδια χρονικά όρια,
για να πάρετε μοναδικούς σωλήνες χρονικής δράσης. Στη συνέχεια, ταξινομούμε όλες τις προτεινόμενες
σωλήνες δράσης ακριβώς όπως κάναμε στο βήμα 3 προηγουμένως. Μετά από αυτό, θα εκτελέσουμε
με τις βαθμολογίες εμπιστοσύνης που εξάγονται από το τελευταίο στρώμα της
3D ResNet34 και τέλος κρατάμε αυτά που το σκορ εμπιστοσύνης τους είναι πάνω από ένα
προκαθορισμένο όριο.
\begin{center}
  % \setlength{\tabcolsep}{2pt}
  \begin{longtable}{|| c | c || c c c ||}

    \hline
    \multirow{2}{*}{\textbf{NMS thresh}} & \multirow{2}{*}{\textbf{Conf thresh}} & {} & \textbf{mAP} & {}  \\
    {} & {} & 0.5 & 0.4 & 0.3\\
    \hline
    \multirow{3}{*}{0.9} & {0.6} & 0.31 & 0.54 & 0.65 \\
    \cline{2-5}
    {} & {0.75} & 0.26 & 0.46 & 0.55 \\
    \cline{2-5}
    {} & {0.85} & 0.2 & 0.39 & 0.49 \\
    \hline
    \multirow{3}{*}{0.7} & {0.6} & 0.66 & 0.95 & 1.22 \\
    \cline{2-5}
    {} & {0.75} & 0.55 & 0.80 & 1.01 \\
    \cline{2-5}
    {} & {0.85} & 0.41 & 0.67 & 0.87 \\
    \hline
    \multirow{3}{*}{0.5} & {0.6} & 0.98 & 1.43 & 1.63 \\
    \cline{2-5}
    {} & {0.75} & 0.75 & 1.14 & 1.29 \\
    \cline{2-5}
    {} & {0.85} & 0.64 & 0.92 & 1.04 \\
    \hline
    \multirow{3}{*}{0.4} & {0.6} & 1.19 & 1.73 & 2.15 \\
    \cline{2-5}
    {} & {0.75} & 0.9 & 1.35 & 1.63 \\
    \cline{2-5}
    {} & {0.85} & 0.79 & 1.16 & 1.38 \\

    \hline
    \multirow{3}{*}{0.3} & {0.6} & 1.12 & 1.85 & 2.23 \\
    \cline{2-5}
    {} & {0.75} & 0.96 & 1.54 &1.7 \\
    \cline{2-5}
    {} & {0.85} & 0.83 & 1.28 & 1.43 \\
    \hline
    \multirow{3}{*}{0.2} & {0.6} & 2.05 & 2.68 & 3.7 \\
    \cline{2-5}
    {} & {0.75} & 1.61 & 2.17 & 3 \\
    \cline{2-5}
    {} & {0.85} & 1.51 & 1.88 & 2.54 \\

    \hline

    \caption{UCF's temporal localization mAP performance}
    \label{table:temp_cls_2}
  \end{longtable}
\end{center}

Συγκρίνοντας τους πίνακες 1,23 και 1,21, έχουμε τα ίδια αποτελέσματα για την επικάλυψη
κατώτατα όρια 0,9, 0,7, 0,5, 0,4 και 0,3. Αλλά για επικάλυψη όριο 0,2 έχουμε παρατηρήσει
Οι επιδόσεις του mAP βελτιώνονται περίπου στο 1%. Έτσι, σκεφτήκαμε ότι θα πρέπει να
να χρησιμοποιούν ακόμη μικρότερα κατώτατα όρια επικάλυψης, τα οποία είναι 0,15, 0,1 και 0,05 τα οποία
παρουσιάζονται στον πίνακα 1,24.

\begin{center}
  \begin{longtable}{|| c | c | c c c||}
    \hline
    \multirow{2}{*}{\textbf{NMS thresh}} & \multirow{2}{*}{\textbf{Conf thresh}} & {} & \textbf{mAP} & {} \\
    {} & {} & 0.5 & 0.4 & 0.3 \\
    \hline
    \multirow{3}{*}{0.15} & 0.6 & 2.01 & 2.66 & 3.62 \\
    \cline{2-5}
    {} & 0.75 & 1.62 & 2.21 & 2.97 \\
    \cline{2-5}
    {} & 0.85 & 1.51 & 1.91 & 2.56 \\
    \hline
    \multirow{3}{*}{0.10} & 0.6 & 1.87 & 2.74 & 3.77 \\
    \cline{2-5}
    {} & 0.75 & 1.62 & 2.28 & 3.08  \\
    \cline{2-5}
    {} & 0.85 & 1.5 & 2 & 2.7  \\
    \hline
    \multirow{3}{*}{0.05} & 0.6 & 1.85 & 2.71 & 3.73  \\
    \cline{2-5}
    {} & 0.75 & 1.61 & 2.28 & 3.1  \\
    \cline{2-5}
    {} & 0.85 & 1.5 & 2 & 2.7 \\
    \hline

    \caption{UCF's temporal localization mAP performance for even smaller NMS threshold}
    \label{table:temp_cls_2_1}

  \end{longtable}
\end{center}

Η χρήση πολύ μικρού κατώτατου ορίου του ΝS οδηγεί σε μια μικρή βελτίωση του mAP
Απόδοση. Ωστόσο, αυτές οι βαθμολογίες απέχουν πολύ από τα υπερκαλλιτεχνικά αποτελέσματα.
Έτσι, νομίζουμε ότι πρέπει να επανεξετάσουμε τον τρόπο που εκπαιδεύσαμε την τάξη μας και την
τον τρόπο με τον οποίο ταξινομεί τους σωλήνες δράσης, προκειμένου να είναι σε θέση να ταξινομήσει αποτελεσματικά.
Αυτή η έρευνα έχει απομείνει για μελλοντικές εργασίες, και δεν θα γίνει ανάληψη καθηκόντων σε αυτή τη διατριβή.

\end{document}